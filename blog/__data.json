{"type":"data","nodes":[{"type":"data","data":[{"footer":1},{"html":2,"slug":3,"uuid":4,"created":5,"date":6,"published":7,"abstract":8,"tags":9,"links":-1,"type":10,"cover_image":-1,"description":11,"folder":12},"\u003Cp>Built with SvelteKit and hosted on GitHub Pages.\u003C/p>\n\u003Cp>View this website on \u003Ca href=\"https://github.com/Tiim/Tiim.github.io\" rel=\"nofollow noopener noreferrer\">GitHub\u003C/a>!\u003C/p>\n\u003Ch2>Other pages\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://tiim.ch/pages/links\" rel=\"nofollow noopener noreferrer\">Links and Blogroll\u003C/a>\u003C/li>\n\u003C/ul>","footer","e556fd14-3acd-4a7b-9b31-929fdd6d2b7a",["Date","2023-07-31T20:16:19.000Z"],["Date","2023-07-31T20:16:19.000Z"],true,"\u003Cp>Built with SvelteKit and hosted on GitHub Pages.\u003C/p>",[],"article","","metadata"],"uses":{}},{"type":"data","data":[{"posts":1},[2,23,39,57,73,91,109,124,139,160,180,198,214,229,245,259,276,290],{"html":3,"slug":4,"uuid":5,"date":6,"created":7,"aliases":8,"title":9,"published":10,"modified":8,"description":11,"cover_image":12,"cover_image_txt":13,"content_tags":14,"abstract":19,"tags":20,"links":-1,"type":21,"folder":22},"\u003Cblockquote class=\"callout callout-note\">\n\u003Cspan class=\"callout-title\">\u003Cspan class=\"callout-icon\">\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\">\u003Cpath d=\"M64 32C28.7 32 0 60.7 0 96v320c0 35.3 28.7 64 64 64h226.7c17 0 33.3-6.7 45.3-18.7l93.3-93.3c12-12 18.7-28.3 18.7-45.3V96c0-35.3-28.7-64-64-64zm0 64h320v224h-64c-17.7 0-32 14.3-32 32v64H64z\">\u003C/path>\u003C/svg>\u003C/span>Note\u003C/span>\u003Cp>This post is meant as a reference for myself. I only published it in case someone else might find it interesting.\nI did not spend much time on this post.\u003C/p>\n\u003C/blockquote>\n\u003Cp>I do host some services on a few rented VPS servers and on my \"home lab\", which is just an old desktop that is running in the basement.\nWhen I got into self-hosting, I decided I would host everything exclusively in docker, which has served me pretty well over the last few years. In the last while I\nhave learned a lot about Kubernetes, and am strongly considering switching my \"simple\" hosting setup for a more complex Kubernetes cluster. So before I do that I want\nto write down what my current setup looks like.\u003C/p>\n\u003Ch2>Setup\u003C/h2>\n\u003Cp>\u003Cimg src=\"https://media.tiim.ch/0887e318-9359-4753-abaf-49ae7c26dfcd.webp\" alt=\"\">\u003C/p>\n\u003Cp>As mentioned, everything is hosted in docker containers. Generally, I try to keep everything in docker-compose, since this allows me to specify the settings of the container once, and easily modify it later.\nTo have multiple services available on port 80 and 443, I use the Traeffik (Software) reverse proxy. I use Traefik without a config file, meaning it pulls the routes and rules directly from the labels of the\nrunning containers on the VPS. This makes it easy to launch a new service and have its reverse proxy config directly in the docker-compose file.\u003C/p>\n\u003Cp>Since many services use a database, and Postgres seems to be supported by many open-source projects, I decided to have a central Postgres instance running in a docker container. This allows me to\nback it up with a simple cron job in a single place. If a service does not support Postgres, I specify its database directly in the docker-compose file.\u003C/p>\n\u003Cp>Almost all services use disk access for either config, local files, or similar. I do have a docker folder that is the root of all locally stored files.\u003C/p>\n\u003Ch2>OS Setup\u003C/h2>\n\u003Cp>When I first started, I configured everything by hand, and documented how, why, and what I did. However I was not happy with this, I could not test it out and it was prone to errors.\nTherefore, I decided to use Ansible to set up the server and install all dependencies.\nThis worked well, so well that I decided that Ansible was good enough to use to operate the entire pipeline, even to automate the deployment of the services.\u003C/p>\n\u003Ch2>Deployment\u003C/h2>\n\u003Cp>I do have an ansible role per service, with its configuration (mostly) as ansible YAML files, and the docker-compose files and other config files as ansible templates. This worked great, with a single ansible-playbook command I can\nmake sure everything is running and has the right config.\nFor most services, I even built logic to make sure that when the docker-compose file or a config file changes, the container is restarted.\u003C/p>\n\u003Ch2>The good parts\u003C/h2>\n\u003Cp>I am quite happy with this system in general. Everything runs stable, backups are easy and automated, and deployments for services that are already configured are a breeze.\nI can keep the whole \"description\" of what is running in a single git repo, and make changes by editing config files.\nThis is a huge step up from manually deploying and keeping track of what docker commands to use for what service.\u003C/p>\n\u003Ch2>The not so good parts\u003C/h2>\n\u003Cp>Recently I noticed some pain points.\u003C/p>\n\u003Col>\n\u003Cli>If I want to deploy a service twice for two domain names, I have to create a copy of the role. This unfortunately leads to duplicated \"code\" which can (and does) lead to configuration drift.\u003C/li>\n\u003Cli>I have to code things myself that already exist. For example, restarting a container when a config value changes. For most services this is implemented, but not everywhere, and also not for all possible things that can be changed. This is not what I want to be concentrating on if I am writing the config to deploy a service.\u003C/li>\n\u003C/ol>\n\u003Cp>In general, I seem to have built a worse subset of Kubernetes myself, just without the robustness that makes Kubernetes so interesting.\u003C/p>\n\u003Ch2>My plan for the future\u003C/h2>\n\u003Cp>I am planning to replace docker with Kubernetes, specifically K3s (Software), a very lightweight and mostly \"batteries included\" Kubernetes distribution.\nAnsible will stay, but only as a tool to set up and configure the OS, install dependencies, and install and run K3S. Deployment of services I either want to do directly using the kubectl command line tool, or more likely using\nArgoCD, a project that pulls Kubernetes manifests from a Git repository and automatically deploys it.\u003C/p>\n\u003Cp>For the configuration, I will take a look at Helm (Software).\u003C/p>","blog/2023-12-03-my-selfhosting-setup","3af67a63-5f3a-422c-8aee-5e3daa8921f9",["Date","2023-12-04T08:00:00.000Z"],["Date","2023-12-03T21:08:16.000Z"],null,"My Selfhosting Setup",true,"A short overview on how I self-host.","https://media.tiim.ch/4a0a43eb-cf95-4273-b6a6-e085c9123985.webp","Model: realvisxlV20_v20Bakedvae; beach sunset, palms, calm ocean, fine sand, cinematic shot, photorealistic ## (worst quality)",[15,16,17,18],"ansible","docker","traefik","server","\u003Cp>[!NOTE]\nThis post is meant as a reference for myself. I only published it in case someone else might find it interesting.\nI did not spend much time on this post.\u003C/p>",[15,16,18,17],"article","blog",{"html":24,"slug":25,"uuid":26,"date":27,"created":28,"aliases":8,"title":29,"published":10,"modified":8,"description":30,"cover_image":31,"cover_image_txt":32,"content_tags":33,"abstract":37,"tags":38,"links":-1,"type":21,"folder":22},"\u003Cp>I recently had to find a way to delete a folder using Ansible that was being created by Docker. The folder had a path like \u003Ccode>~/docker/myservice\u003C/code>. Since docker had created it as part of a volume, the folder did not belong to the current user. So deleting the folder using normal permissions failed.\u003C/p>\n\u003Cp>Deleting with elevated permission on the command line is easy: The command \u003Ccode>sudo rm -rf ~/docker/myservice\u003C/code> performs the \u003Ccode>rm\u003C/code> operation as the root user. In bash, this will delete the \u003Ccode>docker/myservice\u003C/code> folder in the user's home directory, but when doing the equivalent in Ansible, this won't work!\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-yaml\"># This does not work!\n- name: Delete the folder using root permissions\n  become: true\n  ansible.builtin.file:\n    path: \"~/docker/myservice\"\n    state: \"absent\"\n\u003C/code>\u003C/pre>\n\u003Cp>This code will try to delete the file \u003Ccode>/user/root/docker/myservice\u003C/code>, which is not what we wanted.\u003C/p>\n\u003Cp>The bash version works because the shell first resolves the tilde in the argument to the current users' directory before calling the sudo command. In Ansible, we first switch to the root user and only then the tilde is resolved: this time to the home directory of the root user.\u003C/p>\n\u003Cp>To circumvent this, we can manually resolve the path to an absolute path. Unfortunately, I have not found a straightforward way to do this in Ansible, however the bash command \u003Ccode>readlink -f &#x3C;path>\u003C/code> does exactly this. To use it in Ansible, we can use the following configuration:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-yaml\">- name: Get absolute folder path\n  ansible.builtin.command:\n    cmd: \"readlink -f ~/docker/myservice\"\n  register: folder_abs\n  changed_when: False\n\n- name: Debug\n  debug:\n    msg: \"{{folder_abs.stdout}}\" # prints /user/tim/docker/myservice\n\n- name: Delete the folder using root permissions\n  become: true\n  ansible.builtin.file:\n    path: \"{{folder_abs.stdout}}\"\n    state: \"absent\"\n\u003C/code>\u003C/pre>\n\u003Cp>With this Ansible script, we manually resolve the absolute path and use it to delete the folder using root permissions. If you know of an easier way to resolve to an absolute path, please let me know!\u003C/p>","blog/2023-09-20-ansible-absolute-path","ad58acaf-56b0-4bcf-9b72-d6c054fc48d4",["Date","2023-09-20T21:39:13.000Z"],["Date","2023-09-20T20:22:35.634Z"],"Getting the Absolute Path of a Remote Directory in Ansible","There is no builtin way to convert a relative path to an absolute path in ansible. However we can use the readlink command for this.","https://media.tiim.ch/3c1246e4-3201-4df6-af87-6aa4ab98800e.webp","(stable doodle) server room, neon, cables",[34,15,35,36],"dev","linux","bash","\u003Cp>I recently had to find a way to delete a folder using Ansible that was being created by Docker. The folder had a path like \u003Ccode>~/docker/myservice\u003C/code>. Since docker had created it as part of a volume, the folder did not belong to the current user. So deleting the folder using normal permissions failed.\u003C/p>",[15,36,34,35],{"html":40,"slug":41,"uuid":42,"date":43,"created":44,"aliases":45,"title":46,"published":10,"modified":8,"description":47,"cover_image":48,"cover_image_txt":49,"content_tags":50,"abstract":55,"tags":56,"links":-1,"type":21,"folder":22},"\u003Cp>My first real programming experience was with a scripting language called \u003Ca href=\"https://www.autohotkey.com/\" rel=\"nofollow noopener noreferrer\">AutoHotkey\u003C/a>. This was before I was fluent enough in English to join the English-speaking community around this language. But luckily, there was an official German forum. It was really active, not only consisting of newcomers to the language but also veterans. When I joined this forum in my teens I quickly went from just asking beginner questions, to enjoying helping other beginners, that asked the same questions as I did previously. I got better at the language, learned new programming concepts all through reading posts, helped others, and shared my projects on this forum. I got excited when I saw a post from other users that I recognized.\nWhen AutoHotkey got forked and the new interpreter introduced classes and object-oriented programming, I felt in way over my head. Since I was not alone in this, one person took the time to write an incredibly detailed guide as a forum post. I recently found this post printed on paper. I had printed it right before going on vacation since I desperately wanted to learn but knew I was not going to have access to the internet for a while.\nUnfortunately, the German forum has since been discontinued, but some of the pages are still up on the \u003Ca href=\"https://web.archive.org/web/20121005080807/http://de.autohotkey.com/forum/\" rel=\"nofollow noopener noreferrer\">Way back machine\u003C/a>.\u003C/p>\n\u003Cp>Another community I used to be really active in, was for a small indie roleplaying game called \u003Ca href=\"\">Illarion\u003C/a>. Again, the community relied heavily on a forum for communications. This time it was used for players to engage in \"out of character\" communication, as well as a way to simulate a metaphorical bullet board in the game town square where characters could leave notes for each other.\nSince the game was closely inspired by TTRPGs like D&#x26;D, the role-playing part was more important than the in-game mechanics. The forum allowed characters to interact with each other that were not online at the same time. Again, I got really invested in this community, even going so far as joining other guild-specific forums.\u003C/p>\n\u003Cp>I eventually moved on from both of those amazing communities, because my interests changed. I left the AutoHotkey community because I started to get more involved with other programming languages, and I left the Illarion community because I (with the support of my parents) was looking for a less time-intensive game. Unfortunately, I never happened to find another online community like those two ever again...\u003C/p>\n\u003Cp>Sometime later I joined Reddit and was amazed. It felt like a place where all communities come together on a single site. No need to check on multiple websites for new posts, everything neatly together in a single website, accessible on a single (third party) app. I remember wondering why people were still using forums when Reddit was so much simpler.\u003C/p>\n\u003Cp>Jumping to the present and I realize that I was wrong. Even though I am subscribed to a bunch of communities on Reddit, I barely comment on any posts and posted even less. While I am a community member on record, I do not feel like one. The wealth of communities, as well as the incentive to go on the front page to see the most popular posts of the whole site, made me want to open Reddit, but it did not give me the feeling of belonging. I rather felt like a spectator that from time to time gathers the courage to shout his own ideas into the ether.\u003C/p>\n\u003Cblockquote>\n\u003Cp>Side note: Discord comes much closer to the feeling of community. However, the nature of chat makes the interactions fleeting, being in a chat room with a few hundred other people, where every message is just a few sentences at most does not lead to the same connections. No one expects their message to be read again after a few days.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Now the company behind Reddit started to lose the goodwill of the users. While I don't think Reddit will die anytime soon, I think there are a lot of people looking for alternatives. And the best alternative to the website that killed forums is... forums.\u003C/p>\n\u003Cp>While forums largely still work the same as they did 15 years ago, there have been developments that might make them more feasible for our desire to have everything accessible on a single site or on a single app. Last time a social media company, Twitter, annoyed its user base, the fediverse, and more specifically Mastodon, started to go more mainstream. This time I hope there will be other projects that profit. I have heard people mentioning the projects Kbin and Lemmy, both forum-like platforms that implement the ActivityPub specification. Same as Mastodon, this means users are able to interact with users on other instances. Even further, this should also allow users of any federated social network, such as Mastodon, to post and comment on any federated forum. Even established forum software such as \u003Ca href=\"https://community.nodebb.org/topic/17117/what-s-next-after-v3/18\" rel=\"nofollow noopener noreferrer\">Flarum\u003C/a> and \u003Ca href=\"https://community.nodebb.org/topic/17117/what-s-next-after-v3/18\" rel=\"nofollow noopener noreferrer\">nodeBB\u003C/a> are considering adding federation support.\u003C/p>\n\u003Cp>I really hope that forums make a comeback, not only because of the nostalgia but also because to me it feels like a more sustainable way to build a community. And now with the possibility to federate via the fediverse, a forum doesn't have to be a walled garden of members any more. In the end, most importantly I hope people are still finding communities they can be as passionate about as I was, without any corporate overlords trying to keep their eyeballs on ads as long as possible.\u003C/p>","blog/2023-06-16-forums","624afba6-2962-4710-9bc7-686702cc9b55",["Date","2023-06-16T18:56:56.000Z"],["Date","2023-06-16T15:09:15.488Z"],[8],"Forums","My experience of using forums in my teens, what changed after I started using reddit and my hopes for internet communities in the future.","https://media.tiim.ch/fe5de393-9773-4eaa-877a-decffbd706b4.webp","Stable Diffusion - bunch people talking to each other, social, speech bubbles, digital art, minimalistic",[51,52,53,54],"forum","fediverse","reddit","activitypub","\u003Cp>My first real programming experience was with a scripting language called \u003Ca href=\"https://www.autohotkey.com/\">AutoHotkey\u003C/a>. This was before I was fluent enough in English to join the English-speaking community around this language. But luckily, there was an official German forum. It was really active, not only consisting of newcomers to the language but also veterans. When I joined this forum in my teens I quickly went from just asking beginner questions, to enjoying helping other beginners, that asked the same questions as I did previously. I got better at the language, learned new programming concepts all through reading posts, helped others, and shared my projects on this forum. I got excited when I saw a post from other users that I recognized.\nWhen AutoHotkey got forked and the new interpreter introduced classes and object-oriented programming, I felt in way over my head. Since I was not alone in this, one person took the time to write an incredibly detailed guide as a forum post. I recently found this post printed on paper. I had printed it right before going on vacation since I desperately wanted to learn but knew I was not going to have access to the internet for a while.\nUnfortunately, the German forum has since been discontinued, but some of the pages are still up on the \u003Ca href=\"https://web.archive.org/web/20121005080807/http://de.autohotkey.com/forum/\">Way back machine\u003C/a>.\u003C/p>",[54,52,51,53],{"html":58,"slug":59,"uuid":60,"date":61,"created":62,"aliases":8,"title":63,"published":10,"modified":64,"description":65,"cover_image":66,"cover_image_txt":8,"content_tags":67,"abstract":71,"tags":72,"links":-1,"type":21,"folder":22},"\u003Ch2>Abstract\u003C/h2>\n\u003Cp>Planning is the process of finding a path in a planning task from the initial state to a goal state. Multiple algorithms have been implemented to solve such planning tasks, one of them being the Property-Directed Reachability algorithm. Property-Directed Reachability utilizes a series of propositional formulas called layers to represent a super-set of states with a goal distance of at most the layer index. The algorithm iteratively improves the layers such that they represent a minimum number of states. This happens by strengthening the layer formulas and therefore excluding states with a goal distance higher than the layer index. The goal of this thesis is to implement a pre-processing step to seed the layers with a formula that already excludes as many states as possible, to potentially improve the run-time performance. We use the pattern database heuristic and its associated pattern generators to make use of the planning task structure for the seeding algorithm. We found that seeding does not consistently improve the performance of the Property-Directed Reachability algorithm. Although we observed a significant reduction in planning time for some tasks, it significantly increased for others.\u003C/p>\n\u003Cp>\u003Ca href=\"https://www.researchgate.net/publication/373994137_Automated_Planning_using_Property-Directed_Reachability_with_Seed_Heuristics\" rel=\"nofollow noopener noreferrer\">Download PDF\u003C/a>\u003C/p>\n\u003Ch2>Cite\u003C/h2>\n\u003Cpre>\u003Ccode class=\"language-bibtex\">@phdthesis{bachmann2023,\n    author = {Bachmann, Tim},\n    year = {2023},\n    month = {05},\n    title = {Automated Planning using Property-Directed Reachability with Seed Heuristics},\n    doi = {10.13140/RG.2.2.11456.30727},\n    type = {Master's Thesis},\n    school = {University of Basel}\n}\n\u003C/code>\u003C/pre>","blog/2023-05-06-pdr-with-seed-heuristics","111e68c4-0285-4f21-ab36-4c1ce1989da1",["Date","2023-05-06T11:15:53.000Z"],["Date","2023-05-06T11:15:53.000Z"],"Automated Planning using Property-Directed Reachability with Seed Heuristics",["Date","2023-09-18T13:32:00.000Z"],"Masters Thesis. The goal of this thesis is to implement a pre-processing step to the Property Directed Reachability algorithm, to potentially improve the run-time performance. We use the pattern database heuristic to make use of the planning task structure for the seeding algorithm.","https://media.tiim.ch/023c1722-ac3d-45fd-b66c-9ff319dfc180.webp",[34,68,69,70],"planning-system","pdr","heuristic","\u003Cp>Planning is the process of finding a path in a planning task from the initial state to a goal state. Multiple algorithms have been implemented to solve such planning tasks, one of them being the Property-Directed Reachability algorithm. Property-Directed Reachability utilizes a series of propositional formulas called layers to represent a super-set of states with a goal distance of at most the layer index. The algorithm iteratively improves the layers such that they represent a minimum number of states. This happens by strengthening the layer formulas and therefore excluding states with a goal distance higher than the layer index. The goal of this thesis is to implement a pre-processing step to seed the layers with a formula that already excludes as many states as possible, to potentially improve the run-time performance. We use the pattern database heuristic and its associated pattern generators to make use of the planning task structure for the seeding algorithm. We found that seeding does not consistently improve the performance of the Property-Directed Reachability algorithm. Although we observed a significant reduction in planning time for some tasks, it significantly increased for others.\u003C/p>",[34,70,69,68],{"html":74,"slug":75,"uuid":76,"date":77,"created":78,"aliases":79,"title":80,"published":10,"modified":8,"description":81,"cover_image":82,"cover_image_txt":83,"content_tags":84,"abstract":89,"tags":90,"links":-1,"type":21,"folder":22},"\u003Cp>In one of my last blog posts I \u003Ca href=\"https://tiim.ch/blog/2023-01-15-weechat-docker\" rel=\"nofollow noopener noreferrer\">set up WeeChat in docker\u003C/a>, which works mostly pretty great for me so far. Although, it started to bug me that I felt the need to regularly check IRC in case I missed someone potentially tagging or private-messaging me. While looking around at how I could be notified on mentions and private messages, I found the \u003Ca href=\"https://weechat.org/files/doc/stable/weechat_user.en.html#trigger\" rel=\"nofollow noopener noreferrer\">trigger plugin\u003C/a>. A powerful plugin that comes pre-installed on WeeChat. It lets the user specify a WeeChat command that will be executed when a specific event occurs. This plugin is probably powerful enough to build a small IRC bot, directly in WeeChat.\u003C/p>\n\u003Cp>Also, I recently found the web service \u003Ca href=\"https://ntfy.sh\" rel=\"nofollow noopener noreferrer\">ntfy.sh\u003C/a>. It sends push notifications whenever you send an HTTP post request to a certain URL. I already have ntfy.sh installed on my android phone, and I also found a minimal and lightweight \u003Ca href=\"https://github.com/lucas-bortoli/ntfysh-windows\" rel=\"nofollow noopener noreferrer\">desktop client\u003C/a>.\u003C/p>\n\u003Cp>I managed to set a WeeChat trigger up that fires every time I get mentioned (highlighted in WeeChat terminology), and a trigger that fires every time I get a private message. Both of those triggers execute the \u003Ccode>/exec\u003C/code> command which runs an arbitrary shell command. The exec command runs the \u003Ccode>wget\u003C/code> program to send a post request to the ntfy.sh server, which in turn sends a notification to all apps that subscribe to the same URL as the post request was sent. I would usually use the curl program for this instead of wget, but the docker default docker image doesn't contain a curl install.\u003C/p>\n\u003Cp>Here you can see the two \u003Ccode>/trigger\u003C/code> commands:\u003C/p>\n\u003Cp>\u003Cem>trigger on mention\u003C/em>\u003C/p>\n\u003Cpre>\u003Ccode>/trigger addreplace notify_highlight print '' '${tg_highlight}' '/.*/${weechat.look.nick_prefix}${tg_prefix_nocolor}${weechat.look.nick_suffix} ${tg_message_nocolor}/' '/exec -norc -nosw -bg wget -O- --post-data \"${tg_message}\" \"-                   -header=Title: New highlight: ${buffer.full_name}\" https://ntfy.sh/my_ntfy_topic_1234'\n\u003C/code>\u003C/pre>\n\u003Cp>\u003Cem>trigger on private message\u003C/em>\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-weechat\">/trigger addreplace notify_privmsg print '' '${tg_tag_notify} == private &#x26;&#x26; ${buffer.notify} > 0' '/.*/${weechat.look.nick_prefix}${tg_prefix_nocolor}${weechat.look.nick_suffix} ${tg_message_nocolor}/' '/exec -norc -nosw -bg wget -O- --post-data \"${tg_message}\" \"--header=Title: New private message: ${buffer.full_name}\" https://ntfy.sh/my_ntfy_topic_1234'\n\u003C/code>\u003C/pre>\n\u003Ch2>The trigger commands in detail\u003C/h2>\n\u003Cp>In case you don't just want to copy and paste some random command from the internet into your WeeChat (which you shouldn't do anyway), I will try to explain the trigger command that fires when you get mentioned in a message:\u003C/p>\n\u003Cp>Let's first look at the trigger command itself:\n\u003Ccode>/trigger addreplace &#x3C;name> &#x3C;hook> &#x3C;argument> &#x3C;condition> &#x3C;variable-replace> &#x3C;command>\u003C/code>\nWe call the \u003Ccode>/trigger\u003C/code> command with the \u003Ccode>addreplace\u003C/code> subcommand. This subcommand will either register a new trigger or replace it if one with the same name already exists.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>name\u003C/code> - This argument is self-explanatory, the name of the trigger. In our case I called it \u003Ccode>notify_highlight\u003C/code>, but you could call it whatever you want.\u003C/li>\n\u003Cli>\u003Ccode>hook\u003C/code> - This argument specifies which hook or event the trigger should listen for. WeeChat is built as an event-driven platform, so pretty much anything from mouse movements to IRC messages are handled via events. In this case, we want to trigger on the \u003Ccode>print\u003C/code> event, which is fired every time a new message gets received from IRC.\u003C/li>\n\u003Cli>\u003Ccode>argument\u003C/code> - The argument is needed for some hooks, but not for the \u003Ccode>print\u003C/code> hook, so we are going to ignore that one for now and just set it to an empty string \u003Ccode>''\u003C/code>.\u003C/li>\n\u003Cli>\u003Ccode>condition\u003C/code> - The condition must evaluate to \u003Ccode>true\u003C/code> for the trigger to fire. This is helpful because the \u003Ccode>print\u003C/code> trigger fires for every new message, but we only want to be notified when the new message mentions our nick. The condition for this is \u003Ccode>${tg_highlight}\u003C/code>. You can find the list of variables that you can access with the command \u003Ccode>/trigger monitor\u003C/code>, which prints all variables for every trigger that gets executed.\u003C/li>\n\u003Cli>\u003Ccode>variable-replace\u003C/code> - This took me a while to understand. This command is used to manipulate data and save it to a variable. The syntax is inspired by the sed command. Explaining it fully is out of the scope of this blog post, but you can take a look at the \u003Ca href=\"https://weechat.org/files/doc/devel/weechat_user.en.html#trigger_regex\" rel=\"nofollow noopener noreferrer\">docs\u003C/a>. In our example, we replace the whole content of the variable \u003Ccode>tg_message\u003C/code> with the format string \u003Ccode>${weechat.look.nick_prefix}${tg_prefix_nocolor}${weechat.look.nick_suffix} ${tg_message_nocolor}\u003C/code> which results in a string like \u003Ccode>&#x3C;tiim> Hello world!\u003C/code>.\u003C/li>\n\u003Cli>\u003Ccode>command\u003C/code> - The last argument is the command that gets executed whenever this trigger fires. In our case, we use the \u003Ccode>/execute\u003C/code> command, which starts the wget command which in turn sends a post request to ntfy.sh. Make sure you set the ntfy topic (the part after \u003Ccode>https://ntfy.sh/\u003C/code>) to something private and long enough so that nobody else is going to guess it by accident.\u003C/li>\n\u003C/ul>\n\u003Cp>Don't forget to subscribe to the ntfy topic on your phone or whatever device you want to receive the notification on.\u003C/p>\n\u003Cp>The possibilities with the trigger plugin are endless, I hope this inspires you to build your own customizations using weechat.\u003C/p>","blog/2023-03-28-weechat-notification-ntfy","ef51e944-86fa-44b0-ab9d-be7f8d8e569a",["Date","2023-03-28T10:05:19.000Z"],["Date","2023-01-15T20:35:40.643Z"],[8],"Weechat Notifications with ntfy.sh","Using the weechat trigger plugin to notify yourself about new private messages and mentions through the ntfy.sh notification service.","https://media.tiim.ch/97833b1d-d602-4d9a-9689-3077e96e45ba.webp","stable diffusion - Anything V3.0 - boy using an old DOS computer, 90s vibes, muted pastel colors, stylized, thick lines, IRC, console",[85,86,87,88],"weechat","ntfy.sh","wget","irc","\u003Cp>In one of my last blog posts I \u003Ca href=\"https://tiim.ch/blog/2023-01-15-weechat-docker\">set up WeeChat in docker\u003C/a>, which works mostly pretty great for me so far. Although, it started to bug me that I felt the need to regularly check IRC in case I missed someone potentially tagging or private-messaging me. While looking around at how I could be notified on mentions and private messages, I found the \u003Ca href=\"https://weechat.org/files/doc/stable/weechat_user.en.html#trigger\">trigger plugin\u003C/a>. A powerful plugin that comes pre-installed on WeeChat. It lets the user specify a WeeChat command that will be executed when a specific event occurs. This plugin is probably powerful enough to build a small IRC bot, directly in WeeChat.\u003C/p>",[88,86,85,87],{"html":92,"slug":93,"uuid":94,"date":95,"created":96,"aliases":97,"title":98,"published":10,"modified":8,"description":99,"cover_image":100,"cover_image_txt":101,"content_tags":102,"abstract":107,"tags":108,"links":-1,"type":21,"folder":22},"\u003Cp>I recently ran into the problem that when the Cisco AnyConnect VPN is connected, the network connectivity inside of WSL2 stops working. I found a bunch of solutions online for it: most just focus on the fact that the VPN DNS settings are not applied inside WSL2 and therefore no domain names can be resolved. I additionally had the issue that the WSL2 network interface somehow gets disconnected when the VPN starts.\u003C/p>\n\u003Cp>I will show you how I fixed this problem for me and explain what the commands I used do. This post is mostly for my reference, but I hope it helps anyone else as well.\u003C/p>\n\u003Ch2>Finding out what your problem is\u003C/h2>\n\u003Cp>Let's check first if we have internet access inside WSL2. For this run the ping command with an IP address as a destination:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">ping 8.8.8.8\n\u003C/code>\u003C/pre>\n\u003Cp>If you get something like this as the output, your internet connection is fine, and it's just the DNS nameserver addresses that are misconfigured, you can jump forward to Solution 2.\u003C/p>\n\u003Cpre>\u003Ccode>PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=108 time=4.53 ms\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=108 time=3.94 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=108 time=3.97 ms\n64 bytes from 8.8.8.8: icmp_seq=4 ttl=108 time=3.78 ms\n64 bytes from 8.8.8.8: icmp_seq=5 ttl=108 time=3.77 ms\n64 bytes from 8.8.8.8: icmp_seq=6 ttl=108 time=3.76 ms\n64 bytes from 8.8.8.8: icmp_seq=7 ttl=108 time=3.81 ms\n\u003C/code>\u003C/pre>\n\u003Cp>If you don't get any responses from the ping (i.e. no more output after the \u003Ccode>PING 8.8.8.8 (8.8.8.8) ...\u003C/code> line), you need to configure the WSL and the VPN network adapter metric. Go to Solution 1.\u003C/p>\n\u003Cp>To check if the DNS is working, we can again use the ping command, this time with a domain name:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">ping google.com\n\u003C/code>\u003C/pre>\n\u003Cp>If you get responses, the DNS and your internet connection are working! If not go to Section 2.\u003C/p>\n\u003Ch2>Solution 1: Fixing the Network Adapter\u003C/h2>\n\u003Cp>Run the following two commands in PowerShell as administrator:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-PowerShell\">Get-NetAdapter | Where-Object {$_.InterfaceDescription -Match \"Cisco AnyConnect\"} | Set-NetIPInterface -InterfaceMetric 4000\n\nGet-NetIPInterface -InterfaceAlias \"vEthernet (WSL)\" | Set-NetIPInterface -InterfaceMetric 1\n\u003C/code>\u003C/pre>\n\u003Cp>Let me explain what those two commands do. Both follow the same pattern of listing all network adapters, selecting a specific adapter from the list and setting its \"metric\".\u003C/p>\n\u003Cp>You can imagine an adapter as a virtual network port on the back of your pc or laptop. But instead of sending packets through the wire, the driver for a specific port can do whatever it wants with those packets, in the case of a VPN, the packets get encrypted and forwarded to the internet via another adapter.\u003C/p>\n\u003Cp>The \u003Ca href=\"https://learn.microsoft.com/en-us/windows-server/networking/technologies/network-subsystem/net-sub-interface-metric\" rel=\"nofollow noopener noreferrer\">InterfaceMetric\u003C/a> is a value associated with each adapter that determines the order of those adapters. This allows windows to determine which adapter to prefer over another one.\u003C/p>\n\u003Cp>By setting the interface metric of the Cisco adapter to 4000 and the metric of the WSL adapter to one, we allow the traffic from WSL to flow through the Cisco adapter. To be honest I do not exactly understand why this works but it does.\u003C/p>\n\u003Ch2>Solution 2: Registering the VPN DNS inside of WSL\u003C/h2>\n\u003Cp>Setting the DNS servers is, unfortunately, a little bit more involved than just running two commands, we need to edit the files \u003Ccode>/etc/wsl.conf\u003C/code> and \u003Ccode>/etc/resolv.conf\u003C/code>, and restart wsl in between. Let's get to it:\u003C/p>\n\u003Cp>Edit the file \u003Ccode>/etc/wsl.conf\u003C/code> inside of WSL2 using a text editor. I suggest doing this through the terminal since you need root permissions to do that:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">sudo nano /etc/wsl.conf\n# feel free to use another editor such as vim or emacs\n\u003C/code>\u003C/pre>\n\u003Cp>Most likely this file does not exist yet, otherwise, I suggest you create a backup of the original file to preserve the settings.\u003C/p>\n\u003Cp>Add the following config settings into the file:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-ini\">[network]\ngenerateResolvConf = false\n\u003C/code>\u003C/pre>\n\u003Cp>This will instruct WSL to not override the \u003Ccode>/etc/resolv.conf\u003C/code> file on every start-up. Save the file and restart WSL with the following command so that the changed config takes effect:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">wsl.exe --shutdown\n\u003C/code>\u003C/pre>\n\u003Cp>Now open a PowerShell terminal and list all network adapters with the following command:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-PowerShell\">ipconfig /all\n\u003C/code>\u003C/pre>\n\u003Cp>Find the Cisco AnyConnect adapter and copy the IP addresses in the DNS-Server field. We will need those IPs in the next step.\u003C/p>\n\u003Cp>Start WSL again and edit the \u003Ccode>/etc/resolv.conf\u003C/code> file:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">sudo nano /etc/resolv.conf\n\u003C/code>\u003C/pre>\n\u003Cp>Most likely there is already something in this file, you can discard it. When undoing the changes, WSL will automatically regenerate this file anyway, so you don't need to back it up.\u003C/p>\n\u003Cp>Delete all the contents and enter the IP addresses you noted down in the last step in the following format:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-resolv\">nameserver xxx.xxx.xxx.xxx\n\u003C/code>\u003C/pre>\n\u003Cp>Put each address on a new line, preceded by the string \u003Ccode>nameserver\u003C/code>.\nSave the file and restart WSL with the same command as above:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">wsl.exe --shutdown\n\u003C/code>\u003C/pre>\n\u003Cp>Now open up WSL for the last time and set the immutable flag for the \u003Ccode>/etc/resolv.conf\u003C/code> file:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">chattr +i /etc/resolv.conf\n\u003C/code>\u003C/pre>\n\u003Cp>And for the last time shut down WSL. Your DNS should now be working fine!\u003C/p>\n\u003Ch2>Undoing those changes\u003C/h2>\n\u003Cp>I did not have a need to undo the steps for \u003Ccode>Solution 1\u003C/code>, and I'm pretty sure the metric resets after each system reboot anyway so there is not much to do.\u003C/p>\n\u003Cp>To get DNS working again when not connected to the VPN run the following commands:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">sudo chattr -i /etc/resolv.conf\nsudo rm /etc/resolv.conf\nsudo rm /etc/wsl.conf\nwsl.exe --shutdown\n\u003C/code>\u003C/pre>\n\u003Cp>This will first clear the immutable flag off \u003Ccode>/etc/resolv.conf\u003C/code>, and delete it. Next, it will delete \u003Ccode>/etc/wsl.conf\u003C/code> if you have a backup of a previous \u003Ccode>wsl.conf\u003C/code> file, you can replace it with that. At last, we shutdown WSL again for the changes to take effect.\u003C/p>\n\u003Cp>Unfortunately, this is quite a procedure to get a VPN to work with WSL2, but I'm hopeful that this will soon not be necessairy anymore.\u003C/p>","blog/2023-03-21-anyconnect-wsl2","c67bc4dc-4c96-41b1-afb5-15a99457dedf",["Date","2023-03-15T15:22:04.511Z"],["Date","2023-03-15T15:22:04.511Z"],[8],"Fix Network Connectivity in WSL2 with Cisco AnyConnect VPN","I ran into problems using Cisco AnyConnect VPN from inside of WSL2. I'm sharing my solution as a step-by-step guide for my reference and to help anyone with the same problem.","https://media.tiim.ch/66ca4290-3fc0-450f-977b-f00f888e4af3.webp","Stable Diffusion - Anything V3.0 - 1boy, hacker, in front of computer, back of head visible, vintage neon color scheme, terminal, big monitor",[103,104,105,106],"wsl","vpn","networking","dns","\u003Cp>I recently ran into the problem that when the Cisco AnyConnect VPN is connected, the network connectivity inside of WSL2 stops working. I found a bunch of solutions online for it: most just focus on the fact that the VPN DNS settings are not applied inside WSL2 and therefore no domain names can be resolved. I additionally had the issue that the WSL2 network interface somehow gets disconnected when the VPN starts.\u003C/p>",[106,105,104,103],{"html":110,"slug":111,"uuid":112,"date":113,"created":114,"aliases":115,"title":116,"published":10,"modified":8,"description":117,"cover_image":-1,"cover_image_txt":118,"content_tags":119,"abstract":122,"tags":123,"links":-1,"type":21,"folder":22},"\u003Cp>Today I ran into the an error trying to deploy my go app in docker, where the container refused to start with the extremely helpful message \u003Ccode>exec /app/indiego: no such file or directory\u003C/code>. I had removed the \u003Ccode>CGO_ENABLE=0\u003C/code> variable from the Dockerfile, because I needed to enable cgo for a library. What I found out was that when enabling cgo, the resulting binary is not statically linked anymore and now depends on libc or musl. Since the \u003Ccode>scratch\u003C/code> image does not contain literally anything, the binary can't find the libraries and crashes with the aforementioned error.\u003C/p>\n\u003Cp>To include libc into the container, I simply changed the base image from \u003Ccode>scratch\u003C/code> to \u003Ccode>alpine\u003C/code>, which includes libc. This makes the image slightly larger but this seemed way easier than trying to include libc directly.\u003C/p>\n\u003Cp>As a bonus I got to delete the \u003Ccode>/usr/share/zoneinfo\u003C/code> and \u003Ccode>ca-certificates.crt\u003C/code> files, and rely on those provided by alpine.\u003C/p>\n\u003Cp>You can see the commit to IndieGo \u003Ca href=\"https://github.com/Tiim/IndieGo/commit/63968814de7e39f295386bf398b583aa8bf0411c\" rel=\"nofollow noopener noreferrer\">here\u003C/a>.\u003C/p>","blog/2023-01-24-no-such-file-or-directory-cgo","dd580343-9e0f-4754-93dd-25667e6b5859",["Date","2023-01-24T00:00:00.000Z"],["Date","2023-01-24T20:54:11.330Z"],[8],"\"no such file or directory\" after enabling CGO in Docker","Quick fix for the \"no such file or directory\" error after enabling CGO, when running in a scratch docker image.","",[120,121,16],"go","cgo","\u003Cp>Today I ran into the an error trying to deploy my go app in docker, where the container refused to start with the extremely helpful message \u003Ccode>exec /app/indiego: no such file or directory\u003C/code>. I had removed the \u003Ccode>CGO_ENABLE=0\u003C/code> variable from the Dockerfile, because I needed to enable cgo for a library. What I found out was that when enabling cgo, the resulting binary is not statically linked anymore and now depends on libc or musl. Since the \u003Ccode>scratch\u003C/code> image does not contain literally anything, the binary can't find the libraries and crashes with the aforementioned error.\u003C/p>",[121,16,120],{"html":125,"slug":126,"uuid":127,"date":128,"created":129,"aliases":130,"title":131,"published":10,"modified":132,"description":133,"cover_image":134,"cover_image_txt":135,"content_tags":136,"abstract":137,"tags":138,"links":-1,"type":21,"folder":22},"\u003Cp>I have recently gotten interested in IRC for some reason and have been looking for a client that I like. I have used \u003Ca href=\"https://hexchat.github.io/\" rel=\"nofollow noopener noreferrer\">HexChat\u003C/a> in the past, but I don't really fancy having yet another communications program running on my PC next to discord, zoom, telegram and thunderbird. I have been trying to use the IRC feature of thunderbird, but even though it works, it feels very much like an afterthought.\u003C/p>\n\u003Cp>The one client I have seen mentioned a lot is \u003Ca href=\"https://weechat.org/\" rel=\"nofollow noopener noreferrer\">WeeChat\u003C/a> (not to be confused with WeChat, the Chinese instant messenger). WeeChat runs in the terminal as a \u003Ca href=\"https://en.wikipedia.org/wiki/Text-based_user_interface\" rel=\"nofollow noopener noreferrer\">TUI\u003C/a> and after a while of getting used to (and after enabling 'mouse mode') it seems intuitive enough.\u003C/p>\n\u003Cp>The nice thing about WeeChat running not as a graphical application, is that it makes it possible to run on a server and access it from anywhere over ssh.\u003C/p>\n\u003Cblockquote class=\"callout callout-info\">\n\u003Cspan class=\"callout-title\">\u003Cspan class=\"callout-icon\">\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\">\u003Cpath d=\"M256 512c141.4 0 256-114.6 256-256S397.4 0 256 0 0 114.6 0 256s114.6 256 256 256m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-144c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32\">\u003C/path>\u003C/svg>\u003C/span>INFO\u003C/span>\u003Cp>Except on mobile devices, but weechat has mobile apps that can connect to it directly.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Since I pretty much host all my selfhosted software in docker on a VPS, I was looking if someone already published a docker image for WeeChat. There is a bunch of them, but only \u003Ca href=\"https://hub.docker.com/r/weechat/weechat\" rel=\"nofollow noopener noreferrer\">weechat/weechat\u003C/a> (the official image) is still updated regularly. The docker hub page does not have any documentation, but I managed to find it in the \u003Ca href=\"https://github.com/weechat/weechat-container\" rel=\"nofollow noopener noreferrer\">weechat/weechat-container\u003C/a> github repo.\u003C/p>\n\u003Cp>As it says in the readme on github, you can start the container with\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">docker run -it weechat/weechat\n\u003C/code>\u003C/pre>\n\u003Cp>which will run weechat directly in the foreground.\u003C/p>\n\u003Cblockquote class=\"callout callout-info\">\n\u003Cspan class=\"callout-title\">\u003Cspan class=\"callout-icon\">\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\">\u003Cpath d=\"M256 512c141.4 0 256-114.6 256-256S397.4 0 256 0 0 114.6 0 256s114.6 256 256 256m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-144c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32\">\u003C/path>\u003C/svg>\u003C/span>Info\u003C/span>\u003Cp>Don't skip the \u003Ccode>-it\u003C/code> command line flags. The \u003Ccode>-i\u003C/code> or \u003Ccode>--interactive\u003C/code> keeps stdin open, which is required to send input to weechat. Weechat also closes immediately if the stdin gets closed, which took me a while to figure out.\nThe \u003Ccode>-t\u003C/code> or \u003Ccode>--tty\u003C/code> flag is required to provide a fake tty to the container. I don't really understand what that means but without this you won't see the user interface of weechat.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Running in the foreground is not really that helpful if we want to run weechat on a server, so we need to detach (let it run in the background) from the container with the \u003Ccode>-d\u003C/code> or \u003Ccode>--detach\u003C/code> flag. It also helps to specify a name for the container with the \u003Ccode>--name &#x3C;name>\u003C/code> argument, so we can quickly find the container again later. The docker command now looks like this:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">docker run -it -d --name weechat weechat/weechat\n\u003C/code>\u003C/pre>\n\u003Cp>When we run this command, we will notice that weechat is running in the background. To access it we can run \u003Ccode>docker attach weechat\u003C/code>. To detach from weechat without exiting the container, we can press \u003Ccode>CTRL-p CTRL-q\u003C/code> as described in the \u003Ca href=\"https://docs.docker.com/engine/reference/commandline/attach/#description\" rel=\"nofollow noopener noreferrer\">docker attach reference\u003C/a>\u003C/p>\n\u003Cp>I noticed that there are two versions of the weechat image: a debian version and an alpine linux version. Generally the Alpine Linux versions of containers are smaller than the Debian versions, so I decided to use the alpine version: \u003Ccode>weechat/weechat:latest-alpine\u003C/code>.\u003C/p>\n\u003Cp>With this we are practically done, but if we ever remove and restart the container, all of the chat logs and customisations to weechat will be gone. To prevent this we need to add the config and log files to a volume.\u003C/p>\n\u003Cp>I generally use the folder \u003Ccode>~/docker/(service)\u003C/code> to point my docker volumes to, so I have a convenient place to inspect, modify and back up the data.\u003C/p>\n\u003Cp>Let's create the folder and add the volume to the docker container. I also added the \u003Ccode>--restart unless-stopped\u003C/code> flag to make sure the container gets restarted if it either exits for some reason of if docker restarts.\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">mkdir -p ~/docker/weechat/data\nmkdir -p ~/docker/weechat/config\n\ndocker run -it -d --restart unless-stopped \\\n    -v \"~/docker/weechat/data:/home/user/.weechat\" \\\n    -v \"~/docker/weechat/config:/home/user/.config/weechat\" \\\n    --name weechat weechat/weechat:latest-alpine`\n\u003C/code>\u003C/pre>\n\u003Cp>Running this command on the server is all we need to have weechat running in docker.\u003C/p>\n\u003Cblockquote>\n\u003Cp>But how do I quickly connect to weechat? Do I always have to first ssh into the server and then run docker attach?\u003C/p>\n\u003C/blockquote>\n\u003Cp>Yes but, as almost always, we can simplify this with a bash script:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-bash\">#!/usr/bin/env bash\n\nHOST=&#x3C;ssh host>\nssh -t \"${HOST}\" docker attach weechat\n\u003C/code>\u003C/pre>\n\u003Cp>This bash script starts ssh with the \u003Ccode>-t\u003C/code> flag which tells ssh that the command is interactive.\nCopy this script into your \u003Ccode>~/.local/bin\u003C/code> folder and make it executable.\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">nano ~/.local/bin/weechat.sh\nchmod +x weechat.sh\n\u003C/code>\u003C/pre>\n\u003Cp>And that's it! Running \u003Ccode>weechat.sh\u003C/code> will open an ssh session to your server and attach to the weechat container. Happy Chatting!\u003C/p>\n\u003Cp>If you liked this post, consider subscribing to my blog via \u003Ca href=\"https://tiim.ch/blog/rss.xml\" rel=\"nofollow noopener noreferrer\">RSS\u003C/a>, or on \u003Ca href=\"https://tiim.ch/follow\" rel=\"nofollow noopener noreferrer\">social media\u003C/a>. If you have any questions, feel free to \u003Ca href=\"https://tiim.ch/contact\" rel=\"nofollow noopener noreferrer\">contact me\u003C/a>. I also usually hang out in \u003Ca href=\"irc://irc.libera.chat/##tiim\">\u003Ccode>##tiim\u003C/code> on irc.libera.chat\u003C/a>. My name on IRC is \u003Ccode>tiim\u003C/code>.\u003C/p>\n\u003Cblockquote class=\"callout callout-info\">\n\u003Cspan class=\"callout-title\">\u003Cspan class=\"callout-icon\">\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\">\u003Cpath d=\"M256 512c141.4 0 256-114.6 256-256S397.4 0 256 0 0 114.6 0 256s114.6 256 256 256m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-144c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32\">\u003C/path>\u003C/svg>\u003C/span>Update 2022-01-18\u003C/span>\u003Cp>I have found that at the beginning of a session, the input to weechat doesn't seem to work. Sometimes weechat refuses to let me type anything and/or doesn't recognize mouse events.\nAfter a while of spamming keys and \u003Ccode>Alt-m\u003C/code> (toggle mouse mode), it seems to fix itself most of the time.\nI have no idea if thats a problem with weechat, with docker or with ssh, and so far have not found a solution for this. If you have the same problem or even know how to fix it, feel free to reach out.\u003C/p>\n\u003C/blockquote>","blog/2023-01-15-weechat-docker","889ff4db-3ccb-4ab1-9676-a2b0ea8f19eb",["Date","2023-01-15T00:00:00.000Z"],["Date","2023-01-15T00:17:07.000Z"],[8],"Running the WeeChat IRC Client on a VPS in Docker",["Date","2023-01-18T11:34:27.000Z"],"Walkthrough on how to setup the WeeChat IRC client in docker.","https://media.tiim.ch/a28c65a1-ed95-43d3-af87-a2ad222bee7f.jpg","Stable Diffusion - anime landscape, pastel colors, thick outlines, forest, mountains, golden light",[88,85,16],"\u003Cp>I have recently gotten interested in IRC for some reason and have been looking for a client that I like. I have used \u003Ca href=\"https://hexchat.github.io/\">HexChat\u003C/a> in the past, but I don't really fancy having yet another communications program running on my PC next to discord, zoom, telegram and thunderbird. I have been trying to use the IRC feature of thunderbird, but even though it works, it feels very much like an afterthought.\u003C/p>",[16,88,85],{"html":140,"slug":141,"uuid":142,"date":143,"aliases":144,"title":145,"published":10,"modified":8,"description":146,"cover_image":147,"cover_caption":148,"content_tags":149,"abstract":154,"tags":155,"links":-1,"type":21,"folder":22},"\u003Cblockquote class=\"callout callout-warning\">\n\u003Cspan class=\"callout-title\">\u003Cspan class=\"callout-icon\">\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\">\u003Cpath d=\"M256 32c14.2 0 27.3 7.5 34.5 19.8l216 368c7.3 12.4 7.3 27.7.2 40.1S486.3 480 472 480H40c-14.3 0-27.6-7.7-34.7-20.1s-7-27.8.2-40.1l216-368C228.7 39.5 241.8 32 256 32m0 128c-13.3 0-24 10.7-24 24v112c0 13.3 10.7 24 24 24s24-10.7 24-24V184c0-13.3-10.7-24-24-24m32 224c0-17.7-14.3-32-32-32s-32 14.3-32 32 14.3 32 32 32 32-14.3 32-32\">\u003C/path>\u003C/svg>\u003C/span>Update May 2024\u003C/span>\u003Cp>Storj has quietly removed their free plan and seems to hold all images on my website for ransom until I\npay for the premium plan. They have not notified my about this happening.\u003C/p>\n\u003Cp>If you pay for the premium version Storj might still work for you, but after this, I personnaly won't trust them with my data again!\u003C/p>\n\u003C/blockquote>\n\u003Cp>For a while now I have been looking for a way to put images on my website. At first I just embedded them in the website github repository, but this just doesn't feel right. Putting one or two image assets in a codebase is one thing, putting an ever growing list of images in there feels icky to me. For this reason I put the last few cover images of my blog posts on the imgur platform. This is slightly cleaner from a git standpoint but now i have to trust imgur to keep serving these images. Additionally, as I recently discovered, this seems to be against imgurs \u003Ca href=\"https://imgur.com/tos\" rel=\"nofollow noopener noreferrer\">TOS\u003C/a>:\u003C/p>\n\u003Cblockquote>\n\u003Cp>[...] Also, don't use Imgur to host image libraries you link to from elsewhere, content for your website, advertising, avatars, or anything else that turns us into your content delivery network.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Finally when I started \u003Ca href=\"https://tiim.ch/blog/2022-12-indiewebifying-my-website-part-1\" rel=\"nofollow noopener noreferrer\">indie-webifying my website\u003C/a>, and was implementing the micropub protocol (which I will blog about at a later time), I decided that it was at the time to host the images on a platform that was meant to do that. I looked at a few storage providers such as cloudinary and S3 based object storage and landed on \u003Ca href=\"https://storj.io/\" rel=\"nofollow noopener noreferrer\">Storj.io\u003C/a>, mostly because of the generous free tier, which should suffice for this little blog for quite a while.\u003C/p>\n\u003Cp>One thing that bothered me slightly was that all storage providers I looked at charge for traffic. It's not the fact that it's an additional expense (if your not in the free tier anymore) that bothers me, but the fact that I don't have any control over how much this will cost me. In all likelihood this will never cost me anything since this blog has not much traffic, but if a post were to go viral (one can dream...), this could result in a surprise bill at the end of the month.\u003C/p>\n\u003Cp>To help with the traffic costs I decided to try to use the free CDN functionality of Cloudflare to reduce the traffic to Storj. In this blog post I will describe how I did that.\u003C/p>\n\u003Ch2>Is this the right solution for you?\u003C/h2>\n\u003Cp>If you are in a similar situation as me, and just want to have somewhere to host your images for a personal website or to share images or screenshots as links while still having control over all your data, this could be a good solution.\u003C/p>\n\u003Cp>If you want to build a robust image pipeline with resizing and image optimization, or you are building an enterprise website this is probably not the right way. You should take a look at cloudinary or one of the big cloud providers.\u003C/p>\n\u003Ch2>Prerequisites\u003C/h2>\n\u003Cp>To use Cloudflare as a CDN, you need to have Cloudflare setup as your DNS host for the domain you want to serve the images from. Even if you just want to use a subdomain like \u003Ccode>media.example.com\u003C/code>, the whole \u003Ccode>example.com\u003C/code> domain needs to be on cloudflare. For me this was not much of an issue, I followed the instructions from cloudflare and pointed the nameserver of my domain to cloudflare. Although I did have an issue during the migration, which resulted in my website being down for two hours. But I'm pretty sure this was caused by my previous nameserver provider.\u003C/p>\n\u003Ch2>Setting up Storj &#x26; Cloudflare\u003C/h2>\n\u003Cp>I assume you already have an account at \u003Ca href=\"https://storj.io/\" rel=\"nofollow noopener noreferrer\">storj.io\u003C/a>. The next step is creating a bucket for your images. A bucket is just a place for your files and folders to live in storj, just like in any other S3 compatible storage provider. (Actually there are no folders in storj and other S3 services, the folders are just prefixes of the filenames). When creating a bucket, make sure you save the passphrase securely, such as in your password manager. Whenever storj asks you for the passphrase, make sure you don't let storj generate a new one! Every new passphrase will create access to a new bucket.\u003C/p>\n\u003Cp>The next step is \u003Ca href=\"https://docs.storj.io/dcs/downloads/download-uplink-cli\" rel=\"nofollow noopener noreferrer\">installing the uplink cli\u003C/a>. Follow the quick start tutorial to \u003Ca href=\"https://docs.storj.io/dcs/getting-started/quickstart-uplink-cli/uploading-your-first-object\" rel=\"nofollow noopener noreferrer\">get an access grant\u003C/a>. Remember to use the same passphrase from above. Now follow the next quickstart tutorial to \u003Ca href=\"https://docs.storj.io/dcs/getting-started/quickstart-uplink-cli/uploading-your-first-object/set-up-uplink-cli\" rel=\"nofollow noopener noreferrer\">add the bucket to the uplink cli\u003C/a>. The file \u003Ccode>accessgrant.txt\u003C/code> in the tutorial only contains the access-grant string that you got from the last step.\u003C/p>\n\u003Cp>Finally we want to share the bucket so the images can be accessed from the web. For this you can run the following command:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">uplink share --dns &#x3C;domain> sj://&#x3C;bucket>/&#x3C;prefix> --not-after=none\n\u003C/code>\u003C/pre>\n\u003Cp>Replace \u003Ccode>&#x3C;domain>\u003C/code> with the domain you want to serve the images from. In my case I use \u003Ccode>media.tiim.ch\u003C/code>. Then replace \u003Ccode>&#x3C;bucket>\u003C/code> with the name of your bucket and \u003Ccode>&#x3C;prefix>\u003C/code> with the prefix.\u003C/p>\n\u003Cp>As mentioned above, you can think of a prefix as a folder. If you use for example \u003Ccode>media-site1\u003C/code> as a prefix, then every file in the \"folder\" \u003Ccode>media-site1\u003C/code> will be shared. This means you can use multiple prefixes to serve files for multiple websites in the same bucket.\u003C/p>\n\u003Cp>You will get the following output:\u003C/p>\n\u003Cpre>\u003Ccode>[...]\n=========== DNS INFO =====================================================================\nRemember to update the $ORIGIN with your domain name. You may also change the $TTL.\n$ORIGIN example.com.\n$TTL    3600\nmedia.example.com           IN      CNAME   link.storjshare.io.\ntxt-media.example.com       IN      TXT     storj-root:mybucket/myprefix\ntxt-media.example.com       IN      TXT     storj-access:totallyrandomstringofnonsens\n\u003C/code>\u003C/pre>\n\u003Cp>Create the DNS entries in Cloudflare with the values printed in the last three lines. Make sure you enable the proxy setting when entering the CNAME entry to enable Cloudflares CDN service.\u003C/p>\n\u003Cp>And that's it. All files you put in the bucket with the correct prefix are now available under your domain! :)\u003C/p>\n\u003Cp>If this blog post helped you, or you have some issues or thoughts on this, leave a comment via the comment box below or via webmention.\u003C/p>","blog/2022-12-storj-cloudflare-image-hosting","6d5a964d-328e-43d7-9189-40280b012074",["Date","2022-12-03T13:37:33.000Z"],[8],"Hosting Images with Storj and Cloudflare","Learn how to setup affordable image hosting for your personal website with Storj.io and Cloudflare.","https://media.tiim.ch/d280fad4-632a-4b5a-b6b2-6a5c0026b61c.jpg","Image generated by Dall-E: travel postcards scattered on grass, top down view, photoreal",[150,151,152,153],"CDN","IndieWeb","Cloudflare","Storj","\u003Cp>[!WARNING] Update May 2024\nStorj has quietly removed their free plan and seems to hold all images on my website for ransom until I\npay for the premium plan. They have not notified my about this happening.\u003C/p>",[156,157,158,159],"cdn","cloudflare","indieweb","storj",{"html":161,"slug":162,"uuid":163,"date":164,"aliases":165,"title":166,"published":10,"modified":167,"description":168,"cover_image":169,"content_tags":170,"syndication":175,"abstract":177,"tags":178,"links":-1,"type":21,"folder":22},"\u003Cp>A few weeks ago, I stumbled on one of \u003Ca href=\"https://www.jvt.me/posts/2019/08/21/rsvp-from-your-website/\" rel=\"nofollow noopener noreferrer\">Jamie Tanna's blog posts about microformats2\u003C/a> by accident. That is when I first learned about the wonderful world of the \u003Ca href=\"https://indieweb.org/why\" rel=\"nofollow noopener noreferrer\">IndieWeb\u003C/a>. It took me a while to read through some of the concepts of the IndieWeb like webmentions, IndieAuth, microformats and all the other standards, but the more I found out about it the more I wanted to play around with it. And what better place to try out new technology than on a personal website?\u003C/p>\n\u003Ch2>The IndieWeb\u003C/h2>\n\u003Cp>I will start with a brief introduction for the uninitiated. If you have already heard about the IndieWeb, feel free to skip to the next section.\u003C/p>\n\u003Cp>The IndieWeb is a collection of standards, intending to make the web social, without the user giving up ownership of their data. While on social media platforms (or as called in IndieWeb terms: silos) you can easily communicate with others, you are always subject to the whims of those platforms.\u003C/p>\n\u003Cp>The IndieWeb wants to solve this by defining standards that, once implemented in a website, allow it to communicate with other websites that are also part of the IndieWeb.\u003C/p>\n\u003Cp>The most important concept of the IndieWeb is, you have control over your data. All of your shared data lives on a domain you control.\u003C/p>\n\u003Cp>Some of the standards in the IndieWeb include:\u003C/p>\n\u003Cul>\n\u003Cli>Microformats2: a way to add structured data to the HTML source code of a website so machines can interpret the data.\u003C/li>\n\u003Cli>Webmentions: a simple communication protocol between websites. It can be used to show comments, likes, bookmarks and more on one website, while the data stays on another website.\u003C/li>\n\u003Cli>IndieAuth, an OAuth2-based way to log in using only your domain name.\u003C/li>\n\u003C/ul>\n\u003Ch2>The implementation on my website\u003C/h2>\n\u003Cp>As explained in my earlier post \u003Ca href=\"https://tiim.ch/blog/2022-07-12-first-go-project-commenting-api\" rel=\"nofollow noopener noreferrer\">First Go Project: A Jam-stack Commenting API\u003C/a>, my website is a statically built SvelteKit app hosted on GitHub Pages. This means the most important part of the IndieWeb is already implemented: I own this domain and post my content here.\u003C/p>\n\u003Ch3>Making the website machine-readable with Microformats\u003C/h3>\n\u003Cp>As mentioned above, the microformats2 standard allows websites to encode data about the page in a machine-readable format. This is accomplished by annotating HTML elements with some predefined class names. For example, the microformat for a blog post, note and other content is called \u003Ca href=\"http://microformats.org/wiki/h-entry\" rel=\"nofollow noopener noreferrer\">h-entry\u003C/a>. By adding the \u003Ccode>h-entry\u003C/code> class to a div, its content is marked as belonging to that post. Children of this div can in turn have other microformat elements such as \u003Ccode>p-name\u003C/code>, \u003Ccode>p-author\u003C/code> or \u003Ccode>dt-published\u003C/code>.\u003C/p>\n\u003Cp>While these CSS classes make the data machine-interpretable, the same data is still available to the user. There is no duplication like for example the meta tags in OpenGraph.\u003C/p>\n\u003Cp>Since my page is a custom SvelteKit app, it was easy enough to add the CSS classes to the right places. I even took the opportunity to add some more information to the pages, like the author card you see if you scroll to the bottom of this post.\u003C/p>\n\u003Ch3>Accepting comments and other interactions via Webmentions\u003C/h3>\n\u003Cp>The standard I wanted to play around with the most are webmentions. A webmention is a sort of notification sent from one website A to another website B, telling B that A has a page linking to it.\u003C/p>\n\u003Cp>In the IndieWeb all types of interactions are just web pages. The microformats2 specification for example allows replies, quotes, likes, bookmarks and many other types of interactions. The receiver of the webmention is free to extract any relevant information from the sender page and might display it, for example as a comment.\u003C/p>\n\u003Cp>Since I already have a \u003Ca href=\"https://github.com/Tiim/IndieGo\" rel=\"nofollow noopener noreferrer\">small custom service\u003C/a> running for the comment section on this site, I decided to add support to it for receiving webmentions. I refactored the comment system quite a bit to make it more modular and extendable, to allow me to add webmentions\u003C/p>\n\u003Cp>It currently supports all the required and some optional features for receiving webmentions: The first thing it does is validate the mention. A mention is only valid if the source and target URLs are valid and if the page from the source URL links to the target URL. The next step is extracting some microformat content from the source URL and saving it to the database.\nI found some things unexpectedly tricky to implement: for example, a repeated webmention with the same source URL should update the previously saved webmention if the link to the target page is still there, but delete the webmention if the link was removed.\u003C/p>\n\u003Cp>I have tested my webmentions implementation using \u003Ca href=\"https://webmention.rocks\" rel=\"nofollow noopener noreferrer\">webmention.rocks\u003C/a>, but I would appreciate it if you left me a mention as well \u003C/p>\n\u003Ch3>Publishing short-form content such as replies, likes and bookmarks: A notes post type\u003C/h3>\n\u003Cp>The next thing I wanted to add to my website was sending webmentions. But before I implemented that, I wanted a way to publish short content without spamming my blog feed. For this, I created a new post type called \u003Ca href=\"https://tiim.ch/mf2\" rel=\"nofollow noopener noreferrer\">notes\u003C/a>. The list of notes lives on the /mf2 page because I plan to mostly use it to publish notes that contain microformats2 classes such as replies and likes. Another reason I didn't want to make it accessible as the /notes page is that I plan to publish my Zettelkasten notes eventually, but this is a story for another post.\u003C/p>\n\u003Cp>I also used the opportunity to add an RSS feed for all my posts, pages, projects, and notes: \u003Ca href=\"https://tiim.ch/full-rss.xml\" rel=\"nofollow noopener noreferrer\">full-rss.xml\u003C/a>. I do not recommend you subscribe to it unless you are curious about all changes to the content on my website.\u003C/p>\n\u003Ch3>Notifying referenced websites: Sending Webmentions\u003C/h3>\n\u003Cp>Sending webmentions was easy compared to receiving webmentions:\u003C/p>\n\u003Cp>On a regular interval (and on page builds), the server loads the full RSS feed and checks what items have a newer timestamp than the last time. It then extracts a list of all URLs from that feed item and loads the list of URLs that it extracted last time. Then a webmention is sent to all the URLs.\u003C/p>\n\u003Cp>Luckily I did not have to implement any of this myself apart from some glue code to fit it together: I used the library \u003Ca href=\"https://github.com/go-co-op/gocron\" rel=\"nofollow noopener noreferrer\">gocron\u003C/a> for scheduling the regular intervals, \u003Ca href=\"https://github.com/mmcdole/gofeed\" rel=\"nofollow noopener noreferrer\">gofeed\u003C/a> for parsing the RSS feed and \u003Ca href=\"https://willnorris.com/go/webmention\" rel=\"nofollow noopener noreferrer\">webmention\u003C/a> for extracting links and sending webmentions.\u003C/p>\n\u003Ch3>In the future: IndieAuth\u003C/h3>\n\u003Cp>The next thing on my roadmap is implementing IndieAuth. Although not because I have a real use case for it, but because I'm interested in OAuth, the underlying standard, and this seems like a good opportunity to get a deeper understanding of the protocol.\u003C/p>\n\u003Cp>Although, before I start implementing the next things, I should probably focus on writing blog posts first. There is no use in the most advanced blogging system if I can't be bothered to write anything.\u003C/p>\u003Cdiv class=\"mf2\">\u003Cblockquote class=\"syndication\">This post is also on \u003Cul>\u003Cli>\u003Ca class=\"u-syndication\" href=\"https://news.indieweb.org/en\">news.indieweb.org\u003C/a>\u003C/li>\u003C/ul>\u003C/blockquote>\u003C/div>\n","blog/2022-12-indiewebifying-my-website-part-1","3b342241-c414-4670-bd22-03e13d6531b7",["Date","2022-11-12T10:55:14.000Z"],[8],"IndieWebifying my Website Part 1 - Microformats and Webmentions",["Date","2022-12-03T20:56:54.000Z"],"This site now supports sending and receiving webmentions and surfacing structured data using microformats2.","https://i.imgur.com/FpgIBxI.jpg",[151,171,172,173,120,174],"Webmentions","mf2","tiim.ch","indiego",[176],"https://news.indieweb.org/en","\u003Cp>A few weeks ago, I stumbled on one of \u003Ca href=\"https://www.jvt.me/posts/2019/08/21/rsvp-from-your-website/\">Jamie Tanna's blog posts about microformats2\u003C/a> by accident. That is when I first learned about the wonderful world of the \u003Ca href=\"https://indieweb.org/why\">IndieWeb\u003C/a>. It took me a while to read through some of the concepts of the IndieWeb like webmentions, IndieAuth, microformats and all the other standards, but the more I found out about it the more I wanted to play around with it. And what better place to try out new technology than on a personal website?\u003C/p>",[120,174,158,172,173,179],"webmentions",{"html":181,"slug":182,"uuid":183,"date":184,"created":185,"aliases":186,"title":187,"published":10,"modified":8,"description":188,"cover_image":189,"content_tags":190,"abstract":195,"tags":196,"links":-1,"type":21,"folder":22},"\u003Cp>In this blog post, I will explain why server-side rendering with the \u003Ca href=\"https://formidable.com/open-source/urql/docs/api/svelte/\" rel=\"nofollow noopener noreferrer\">urql\u003C/a> GraphQL library is not as straightforward to do with SvelteKit, and how I solved this in my project anyway.\u003C/p>\n\u003Cp>Server-side rendering (SSR) is one of the great features of SvelteKit. I will try to keep this blog post short and will therefore not explain what server-side rendering is and why you should take advantage of it \u003Cem>(you really should!)\u003C/em>. If you want to know more about SSR you can take a look at this article: \u003Ca href=\"https://towardsdev.com/server-side-rendering-srr-in-javascript-a1b7298f0d04\" rel=\"nofollow noopener noreferrer\">A Deep Dive into Server-Side Rendering (SSR) in JavaScript\u003C/a>.\u003C/p>\n\u003Ch2>Background - SSR in SvelteKit\u003C/h2>\n\u003Cp>SvelteKit implements SSR by providing a \u003Ca href=\"https://kit.svelte.dev/docs/load\" rel=\"nofollow noopener noreferrer\">\u003Ccode>load\u003C/code> function\u003C/a> for every layout and page component. If a page or layout needs to perform some asynchronous operation, this should be done inside of this load function. SvelteKit executes this function asynchronously on the server side as well as on the client side and the return value of this function is assigned to the \u003Ccode>data\u003C/code> prop of the associated component. Usually, this asynchronous operation is loading data from an external service, like in the case of this blog post a GraphQL server.\nYou can of course load data directly in the component, but SvelteKit will not wait for this to complete when doing SSR, and the resulting HTML will not include the loaded data.\u003C/p>\n\u003Ch2>Background - @urql/svelte\u003C/h2>\n\u003Cp>The urql library allows us to easily issue GraphQL queries and mutations. Some of the functionality it has to make our lives easier include:\u003C/p>\n\u003Cul>\n\u003Cli>Reloading a query when a query variable changes\u003C/li>\n\u003Cli>Reloading a query after a mutation that touches the same data as the query\u003C/li>\n\u003C/ul>\n\u003Cp>We want to keep these features, even when using urql when doing SSR.\u003C/p>\n\u003Ch2>The Problem\u003C/h2>\n\u003Cp>When implementing SSR in my project, I ran into two problems. I couldn't find any documentation or any articles solving them, so I decided to write down my solutions to those problems in this blog post.\u003C/p>\n\u003Ch3>Problem 1 - Svelte and urql Reactivity\u003C/h3>\n\u003Cp>Let's say we have the following load function, which executes a GraphQL query to load a list of red cars:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-js\">// src/routes/car/+page.js\n\n/** @type {import('./$types').PageLoad} */\nexport function load(event) {\n  const client = createClient({\n    url: config.url,\n    fetch: event.fetch,\n  });\n\n  const carColor = \"red\";\n\n  const cars = client\n    .query(carsQuery, {\n      color: carColor,\n    })\n    .toPromise()\n    .then((c) => c.data?.car);\n\n  return {\n    cars,\n  };\n}\n\u003C/code>\u003C/pre>\n\u003Cp>This example uses the urql method \u003Ccode>client.query\u003C/code> to start a query to get us a list of cars with a red colour (The GraphQL query is not shown but the exact query is not important for this example).\nThe client gets a \u003Ca href=\"https://kit.svelte.dev/docs/load#input-methods-fetch\" rel=\"nofollow noopener noreferrer\">special fetch function\u003C/a> from the event which has a few nice properties, like preventing a second network request on the client side if that same request was just issued on the server-side.\u003C/p>\n\u003Cp>Since the query code is now located in the load function and not in a svelte component, there is no way to easily change the \u003Ccode>carColor\u003C/code> and have urql automatically reload the query. The only way to change the variable is to set the value as a query parameter and read that from the \u003Ccode>event\u003C/code> argument. This however means that we have to refresh the whole page just to reload this query.\u003C/p>\n\u003Cp>The other thing urql does for us, reloading the query when we do a mutation on the same data, will not work with the above code either.\u003C/p>\n\u003Ch3>The solution: A query in the load function and a query in the component\u003C/h3>\n\u003Cp>To fix those two drawbacks we have to add the same query as in the load function to our component code as well. Unfortunately, this means when a user loads the page, it sends a request from the client side, even though the same request got sent from the server side already.\u003C/p>\n\u003Cp>I created a small wrapper function \u003Ccode>queryStoreInitialData\u003C/code> that creates the query inside of the component and intelligently switches from the (possibly stale) data from the load function to the new data. Using this wrapper, the page or layout might look as follows:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-svelte\">&#x3C;script>\n  import { queryStoreInitialData } from \"@/lib/gql-client\"; // The helper function mentioned above\n  import { getContextClient } from \"@urql/svelte\";\n  import { carsQuery } from \"./query\"; // The query\n\n  export let data;\n\n  $: gqlStore = queryStoreInitialData(\n    {\n      client: getContextClient(),\n      query: carsQuery,\n    },\n    data.cars\n  );\n  $: cars = $gqlStore?.data?.car;\n&#x3C;/script>\n\n&#x3C;div>\n  &#x3C;pre>\n    {JSON.stringify(cars, null, 2)}\n  &#x3C;/pre>\n&#x3C;/div>\n\u003C/code>\u003C/pre>\n\u003Col>\n\u003Cli>The native \u003Ccode>queryStore\u003C/code> function gets replaced with the wrapper function.\u003C/li>\n\u003Cli>The initial value of the query is supplied to the wrapper\u003C/li>\n\u003C/ol>\n\u003Cp>Unfortunately, we can not return the query result from the load function directly like this:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-js\">const result = await client.query(cars, {}).toPromise();\n\nreturn {\n  cars: toInitialValue(result),\n};\n\u003C/code>\u003C/pre>\n\u003Cp>This results in the following error:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-stacktrace\">Cannot stringify a function (data.events.operation.context.fetch)\nError: Cannot stringify a function (data.events.operation.context.fetch)\n    at render_response (file:///app/node_modules/@sveltejs/kit/src/runtime/server/page/render.js:181:20)\n    at runMicrotasks (&#x3C;anonymous>)\n    at processTicksAndRejections (node:internal/process/task_queues:96:5)\n    at async render_page (file:///app/node_modules/@sveltejs/kit/src/runtime/server/page/index.js:276:10)\n    at async resolve (file:///app/node_modules/@sveltejs/kit/src/runtime/server/index.js:232:17)\n    at async respond (file:///app/node_modules/@sveltejs/kit/src/runtime/server/index.js:284:20)\n    at async file:///app/node_modules/@sveltejs/kit/src/exports/vite/dev/index.js:406:22\n\u003C/code>\u003C/pre>\n\u003Cp>This is because the query result contains data that is not serializable.\nTo fix this I created the \u003Ccode>toInitialValue\u003C/code> function, which deletes all non-serializable elements from the result. The load function now looks like follows;\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-js\">// src/routes/car/+page.js\nimport { createServerClient, toInitialValue } from \"@/lib/gql-client\";\nimport { parse } from \"cookie\";\nimport { carsQuery } from \"./query\";\n\n/** @type {import('./$types').PageServerLoad} */\nexport const load = async (event) => {\n  const client = createClient({\n    url: config.url,\n    fetch: event.fetch,\n  });\n\n  const result = await client.query(cars, {}).toPromise();\n\n  return {\n    cars: toInitialValue(result),\n  };\n};\n\u003C/code>\u003C/pre>\n\u003Ch3>Problem 2 - Authentication\u003C/h3>\n\u003Cp>We will look at the same \u003Ccode>load\u003C/code> function as #Problem 1 - Svelte and urql Reactivity: the function creates a urql client with the fetch function from the event object and uses this client to send a query.\u003C/p>\n\u003Cp>Sometimes however the GraphQL API requires authentication in the form of a cookie to allow access.\u003C/p>\n\u003Cp>Unfortunately, the \u003Ca href=\"https://kit.svelte.dev/docs/load#input-methods-fetch\" rel=\"nofollow noopener noreferrer\">fetch function that we get from the load event\u003C/a> will only pass the cookies on if the requested domain is the same as the base domain or a more specific subdomain of it. This means if your SvelteKit site runs on \u003Ccode>example.com\u003C/code> and your GraphQL server runs on \u003Ccode>gql.example.com\u003C/code> then the cookies will get forwarded and everything is fine. This however is, in my experience, often not the case. Either you might use an external service for your GraphQL API or you host it yourself and want to use its internal domain.\u003C/p>\n\u003Cp>The only way to pass the cookies on to the GraphQL server, in this case, is by manually setting the cookie header when creating the urql client. This however forces us to use the server-only load function, as we do not have access to the cookie header in the normal load function.\u003C/p>\n\u003Cp>The new code now looks like this:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-js\">// /src/routes/car/+page.server.js\n\n/** @type {import('./$types').PageServerLoad} */\nexport function load(event) {\n  const client = createClient({\n    url: config.url,\n    fetch,\n    fetchOptions: {\n      credentials: \"include\",\n      headers: {\n        // inject the cookie header\n        // FIXME: change the cookie name\n        Cookie: `gql-session=${event.cookies.get(\"gql-session\")}`,\n      },\n    },\n  });\n\n  const cars = client.query(carsQuery, {}).toPromise();\n\n  return {\n    cars: toInitialValue(result),\n  };\n}\n\u003C/code>\u003C/pre>\n\u003Cp>To keep the size of the load functions across my codebase smaller I created a small wrapper function \u003Ccode>createServerClient\u003C/code>:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-js\">// /src/routes/car/+page.server.js\n\n/** @type {import('./$types').PageServerLoad} */\nexport function load(event) {\n  const client = createServerClient(event.cookies);\n\n  const cars = client.query(carsQuery, {}).toPromise();\n\n  return {\n    cars: toInitialValue(result),\n  };\n}\n\u003C/code>\u003C/pre>\n\u003Ch2>The Code\u003C/h2>\n\u003Cp>Below you can find the three functions \u003Ccode>createServerClient\u003C/code>, \u003Ccode>queryStoreInitialData\u003C/code> and \u003Ccode>toInitialValue\u003C/code> that we used above:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-js\">// /src/lib/gql-client.js\n\nimport { browser } from \"$app/environment\";\nimport { urls } from \"@/config\";\nimport { createClient, queryStore } from \"@urql/svelte\";\nimport { derived, readable } from \"svelte/store\";\n\n/**\n * Helper function to create an urql client for a server-side-only load function\n *\n *\n * @param {import('@sveltejs/kit').Cookies} cookies\n * @returns\n */\nexport function createServerClient(cookies) {\n  return createClient({\n    // FIXME: adjust your graphql url\n    url: urls.gql,\n    fetch,\n    // FIXME: if you don't need to authenticate, delete the following object:\n    fetchOptions: {\n      credentials: \"include\",\n      headers: {\n        // FIXME: if you want to set a cookie adjust the cookie name\n        Cookie: `gql-session=${cookies.get(\"gql-session\")}`,\n      },\n    },\n  });\n}\n\n/**\n * Helper method to send a GraphQL query but use the data from the SvelteKit load function initially.\n *\n *\n * @param {any} queryArgs\n * @param {any} initialValue\n * @returns\n */\nexport function queryStoreInitialData(queryArgs, initialValue) {\n  if (!initialValue || (!initialValue.error &#x26;&#x26; !initialValue.data)) {\n    throw new Error(\"No initial value from server\");\n  }\n\n  let query = readable({ fetching: true });\n  if (browser) {\n    query = queryStore(queryArgs);\n  }\n\n  return derived(query, (value, set) => {\n    if (value.fetching) {\n      set({ ...initialValue, source: \"server\", fetching: true });\n    } else {\n      set({ ...value, source: \"client\" });\n    }\n  });\n}\n\n/**\n * Make the result object of a urql query serialisable.\n *\n *\n * @template T\n * @param {Promise&#x3C;import('@urql/svelte').OperationResult&#x3C;T, any >>|import('@urql/svelte').OperationResult&#x3C;T, any >} result\n * @returns {Promise&#x3C;{fetching:false, error: undefined | {name?: string, message?: string; graphQLErrors?: any[]; networkError?: Error; response?: any;}, data: T|undefined}>}\n */\nexport async function toInitialValue(result) {\n  const { error, data } = await result;\n\n  // required to turn class array into array of javascript objects\n  const errorObject = error ? {} : undefined;\n  if (errorObject) {\n    console.warn(error);\n    errorObject.graphQLErrors = error?.graphQLErrors?.map((e) => ({ ...e }));\n    errorObject.networkError = { ...error?.networkError };\n    errorObject.response = { value: \"response omitted\" };\n  }\n\n  return {\n    fetching: false,\n    error: { ...error, ...errorObject },\n    data,\n  };\n}\n\u003C/code>\u003C/pre>\n\u003Cp>\u003Ca href=\"https://gist.github.com/Tiim/1adeb4d74ce7ae09d0d0aa4176a6195d\" rel=\"nofollow noopener noreferrer\">Link to the Gist\u003C/a>\u003C/p>\n\u003Ch2>End remarks\u003C/h2>\n\u003Cp>Even though I think this solution is not too bad, I wish @urql/svelte would implement a better way to handle SSR with sveltekit. I posted a \u003Ca href=\"https://github.com/FormidableLabs/urql/discussions/2703\" rel=\"nofollow noopener noreferrer\">question on the urql GitHub discussions board\u003C/a>, but I have not gotten any response yet.\u003C/p>\n\u003Cblockquote class=\"callout callout-info\">\n\u003Cspan class=\"callout-title\">\u003Cspan class=\"callout-icon\">\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\">\u003Cpath d=\"M256 512c141.4 0 256-114.6 256-256S397.4 0 256 0 0 114.6 0 256s114.6 256 256 256m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-144c-17.7 0-32-14.3-32-32s14.3-32 32-32 32 14.3 32 32-14.3 32-32 32\">\u003C/path>\u003C/svg>\u003C/span>Info\u003C/span>\u003Cp>This article was written with \u003Ccode>@svelte/kit\u003C/code> version \u003Ccode>1.0.0-next.499\u003C/code> and \u003Ccode>@urql/svelte\u003C/code> version \u003Ccode>3.0.1\u003C/code>.\nI will try to update this article as I update my codebase to newer versions.\u003C/p>\n\u003C/blockquote>\n\u003Cp>If this post helped you, or you found a better or different way to solve SSR with urql, please let me know in the comments, write me an email or tag me on twitter \u003Ca href=\"https://twitter.com/TiimB\" rel=\"nofollow noopener noreferrer\">@TiimB\u003C/a>.\u003C/p>","blog/2022-09-27-sveltekit-ssr-with-urql","1e223cab-bca2-4b3b-a75a-71f158c90cba",["Date","2022-09-26T00:00:00.000Z"],["Date","2022-09-26T08:55:23.886Z"],[8],"SvelteKit Server-Side Rendering (SSR) with @urql/svelte","Learn why server-side rendering (SSR) using urql as a GraphQL client is not as straightforward as you might think and how to do it anyway.","https://i.imgur.com/5DBIbbT.png",[191,192,193,194],"urql","sveltekit","SSR","graphql","\u003Cp>In this blog post, I will explain why server-side rendering with the \u003Ca href=\"https://formidable.com/open-source/urql/docs/api/svelte/\">urql\u003C/a> GraphQL library is not as straightforward to do with SvelteKit, and how I solved this in my project anyway.\u003C/p>",[194,197,192,191],"ssr",{"html":199,"slug":200,"uuid":201,"date":202,"created":203,"aliases":204,"title":205,"published":10,"modified":206,"description":207,"cover_image":208,"content_tags":209,"abstract":212,"tags":213,"links":-1,"type":21,"folder":22},"\u003Cp>I recently have been looking around for a simple commenting system to integrate into my website. Since my website is a pre-rendered static Html site hosted on \u003Ca href=\"https://pages.github.com\" rel=\"nofollow noopener noreferrer\">Github Pages\u003C/a>, there is no way for it to directly store comments because it does not have a database. The only option for dynamic content to be stored is with an external service.\u003C/p>\n\u003Cp>I kept my eyes open for a service that I liked, but I did not want to just integrate any old service into my website, I did have some requirements:\u003C/p>\n\u003Cul>\n\u003Cli>The service should not cost anything. I would rather host something myself than sign up for another subscription (because I'm already paying for a VPS anyway).\u003C/li>\n\u003Cli>I want to control how the comments on my website are displayed. I quite like my website design and I don't want a generic comment box below my posts.\u003C/li>\n\u003Cli>The service should respect the privacy of the people using my website.\u003C/li>\n\u003Cli>There should be an option to comment without setting up an account with the service.\u003C/li>\n\u003C/ul>\n\u003Cp>While looking around for how other people integrated comments into their static websites, I found a nice \u003Ca href=\"https://averagelinuxuser.com/static-website-commenting/\" rel=\"nofollow noopener noreferrer\">blog post from Average Linux User\u003C/a> which compares a few popular commenting systems.\nUnfortunately, most systems either are not very privacy-friendly, cost money or store the comments as comments on Github issues..?\nAfter looking through the options I decided to use this opportunity to write my own commenting system and dabble with the Go programming language.\u003C/p>\n\u003Ch2>Writing a commenting API in Go\u003C/h2>\n\u003Cp>First thing first, if you want to take a look at the code, check out the \u003Ca href=\"https://github.com/Tiim/IndieGo\" rel=\"nofollow noopener noreferrer\">Github repo\u003C/a>.\u003C/p>\n\u003Cp>I decided to write the commenting system in Go because I have been looking for an excuse to practice Go for a while, and this seemed like the perfect fit. It is a small CRUD app, consisting of a storage component, an API component and a small event component in the middle to easily compose the functionality I want.\u003C/p>\n\u003Cp>Currently, it supports the following functionality:\u003C/p>\n\u003Cul>\n\u003Cli>Listing all comments (optionally since a specified timestamp)\u003C/li>\n\u003Cli>Listing all comments for a specified page (optionally since a specified timestamp)\u003C/li>\n\u003Cli>Posting comments through the API\u003C/li>\n\u003Cli>A simple admin dashboard that lists all comments and allows the admin to delete them\u003C/li>\n\u003Cli>Email notifications when someone comments\u003C/li>\n\u003Cli>Email notifications when someone replies to your comment\u003C/li>\n\u003Cli>SQLite storage for comments\u003C/li>\n\u003C/ul>\n\u003Cp>The code is built in a way to make it easy to customise the features.\nFor example to disable features like the email reply notifications you can just \u003Ca href=\"https://github.com/Tiim/IndieGo/blob/master/main.go#L52\" rel=\"nofollow noopener noreferrer\">comment out the line in the main.go\u003C/a> file that registers that hook.\u003C/p>\n\u003Cp>To write custom hooks that get executed when a new comment gets submitted or one gets deleted, just implement the \u003Ca href=\"https://github.com/Tiim/IndieGo/blob/master/event/handler.go\" rel=\"nofollow noopener noreferrer\">Handler\u003C/a> interface and register it in the main method.\u003C/p>\n\u003Cp>You can also easily add other storage options like databases or file storage by implementing the \u003Ca href=\"https://github.com/Tiim/IndieGo/blob/master/model/store.go\" rel=\"nofollow noopener noreferrer\">Store and SubscribtionStore\u003C/a> interfaces.\u003C/p>\n\u003Ch2>Can it be used in production? \u003C/h2>\n\u003Cp>I currently use it on this website! Go test it out (I might delete the comments if they are rude though ).\u003C/p>\n\u003Cp>In all seriousness, I would not use it for a website where the comments are critical. But for a personal blog or similar, I don't see why not.\u003C/p>\n\u003Cp>If you want to host your own version, there is a Dockerfile available. If you decide to integrate this into your website, please comment below, ping me \u003Ca href=\"https://twitter.com/TiimB\" rel=\"nofollow noopener noreferrer\">@TiimB\u003C/a> or shoot me an email \u003Ca href=\"mailto:hey@tiim.ch\">hey@tiim.ch\u003C/a>, I would love to check it out.\u003C/p>","blog/2022-07-12-first-go-project-commenting-api","bff14052-4f3f-4dcb-bcee-155ae1c6b09e",["Date","2022-07-12T00:00:00.000Z"],["Date","2022-07-08T16:24:37.766Z"],[8],"First Go Project: A Jam-stack Commenting API",["Date","2022-11-23T21:42:29.000Z"],"I built my first project using the Go programming language: A commenting API for the jam-stack. It is simple but easily extensible. And it powers the commenting feature of this website!","/assets/2022-07-first-go-project-commenting-api.png",[120,210,211,173,174],"web-api","project","\u003Cp>I recently have been looking around for a simple commenting system to integrate into my website. Since my website is a pre-rendered static Html site hosted on \u003Ca href=\"https://pages.github.com\">Github Pages\u003C/a>, there is no way for it to directly store comments because it does not have a database. The only option for dynamic content to be stored is with an external service.\u003C/p>",[120,174,211,173,210],{"html":215,"slug":216,"uuid":217,"date":218,"created":219,"aliases":220,"title":221,"published":10,"modified":8,"description":222,"cover_image":223,"content_tags":224,"abstract":227,"tags":228,"links":-1,"type":21,"folder":22},"\u003Cp>I often go to social media to get news about topics that interest me. Be it web development, gardening life hacks or political news, I can follow people or topics that interest me. But instead of reading about those topics, I often get sucked into an endless hole of content that I did not sign up for. Social media companies deliberately do not want you to limit what is shown to you. It would be too easy to leave and not spend your time watching their precious ads.\u003C/p>\n\u003Cp>But there is another way! By subscribing to RSS feeds you are in control of what you are shown. Most websites, blogs, news sites and even social media sites provide RSS feeds to subscribe to. You get only the articles, videos or audio content you are subscribed to, without any algorithm messing with your attention.\u003C/p>\n\u003Ch2>But what exactly is an RSS feed?\u003C/h2>\n\u003Cp>RSS stands for \"Really Simple Syndication\", and it is a protocol for a website to provide a list of content. It is an old protocol, the first version was introduced in 1999, but it might be more useful nowadays than ever.\nIf you listen to podcasts, you are already familiar with RSS feeds: a podcast is an RSS feed which links to audio files instead of online articles.\nAn RSS feed is just an XML document which contains information about the feed and a list of content.\nWhen you use an app to subscribe to an RSS feed, this app will just save the URL to the XML document and load it regularly to check if new content is available. You are completely in control of how often the feed is refreshed and what feeds you want to subscribe to. Some RSS reader apps also allow you to specify some rules for example about if you should be notified, based on the feed, the content or the tags.\u003C/p>\n\u003Ch2>How to subscribe to a feed?\u003C/h2>\n\u003Cp>Since an RSS feed is just an XML document, you don't \u003Cem>technically\u003C/em> have to subscribe to a feed to read it, you \u003Cem>could\u003C/em> just open the document and read the XML. But that would be painful. Luckily there are several plugins, apps and services that allow you to easily subscribe to and read RSS feeds.\u003C/p>\n\u003Cp>If you want to start using RSS and are not sure if you will take the time to open a dedicated app, I would recommend using an RSS plugin for another software that you are using regularly. For example, the \u003Ca href=\"https://thunderbird.net/\" rel=\"nofollow noopener noreferrer\">Thunderbird\u003C/a> email client already has built-in RSS support. If you want to read to the feeds directly inside of your browser, you can use the \u003Ca href=\"https://nodetics.com/feedbro/\" rel=\"nofollow noopener noreferrer\">feedbro\u003C/a> extension for Chrome, Firefox, and other Chromium-based browsers. I use the \u003Ca href=\"https://vivaldi.com\" rel=\"nofollow noopener noreferrer\">Vivaldi\u003C/a> browser which comes with an integrated RSS feed reader.\u003C/p>\n\u003Ch2>What if there is no RSS feed?\u003C/h2>\n\u003Cp>Unfortunately not every website offers an RSS feed. Although it might be worth it to hunt for them. Some websites offer an RSS feed but do not link to it anywhere.\nIf there is no feed, but a newsletter is offered, the service \"\u003Ca href=\"https://kill-the-newsletter.com\" rel=\"nofollow noopener noreferrer\">Kill The Newsletter\u003C/a>\" will provide you with email addresses and a corresponding RSS URL to convert any newsletter to a feed. Another service to consider is \u003Ca href=\"http://fetchrss.com\" rel=\"nofollow noopener noreferrer\">FetchRSS\u003C/a>. It turns any website into an RSS feed.\u003C/p>\n\u003Ch2>RSS Apps\u003C/h2>\n\u003Cp>If you want to have a dedicated app for your reading, you're in luck! There is a plethora of apps to choose from, all with different features and user interfaces.\nThere are three main types of apps: standalone apps, service-based apps, and self-hosted apps. Most apps are standalone, meaning they fetch the RSS feeds only when open, and don't sync to your other devices. The service-based apps rely on a cloud service which will fetch the feeds around the clock, even when all your devices are off. They can also send you a summary mail if you forget to check for some time and they can sync your subscriptions across all your devices. Unfortunately, most service-based apps only offer a limited experience for free. The last category is self-hosted apps. They are similar to the service based apps but instead of some company running the service, you have to provide a server for the service to run yourself.\u003C/p>\n\u003Cp>I use a standalone app, because I do not want to rely on a service, but I also don't want to go through the hassle of setting up a self-hosted solution.\u003C/p>\n\u003Cp>If you are still unsure what RSS app you could try out, I provided a list below. Make sure to add the \u003Ca href=\"https://tiim.ch/blog/rss.xml\" rel=\"nofollow noopener noreferrer\">RSS feed for my blog\u003C/a> (\u003Ccode>https://tiim.ch/blog/rss.xml\u003C/code>) to test it out \u003C/p>\n\u003Ch3>Standalone Apps\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://thunderbird.net\" rel=\"nofollow noopener noreferrer\">Thunderbird\u003C/a> (Free, OSS)\u003C/li>\n\u003Cli>\u003Ca href=\"https://ravenreader.app\" rel=\"nofollow noopener noreferrer\">RavenReader\u003C/a> (Free, OSS)\u003C/li>\n\u003Cli>\u003Ca href=\"https://netnewswire.com\" rel=\"nofollow noopener noreferrer\">NetNewsWire\u003C/a> (Free, Integration with Services possible)\u003C/li>\n\u003Cli>\u003Ca href=\"https://vivaldi.com\" rel=\"nofollow noopener noreferrer\">Vivaldi Browser\u003C/a> (Free)\u003C/li>\n\u003Cli>\u003Ca href=\"https://nodetics.com/feedbro/\" rel=\"nofollow noopener noreferrer\">feedbro browser extension\u003C/a> (Free)\u003C/li>\n\u003C/ul>\n\u003Ch3>Service-Based Apps\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://feedreader.com\" rel=\"nofollow noopener noreferrer\">FeedReader\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://feeder.co\" rel=\"nofollow noopener noreferrer\">Feeder\u003C/a> (Freemium, 10 feeds for free)\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.inoreader.com/pricing\" rel=\"nofollow noopener noreferrer\">Inoreader\u003C/a> (Freemium, Ads and 150 feeds for free)\u003C/li>\n\u003Cli>\u003Ca href=\"https://newsblur.com\" rel=\"nofollow noopener noreferrer\">NewsBlur\u003C/a> (Freemium, 64 feeds for free)\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.feedspot.com\" rel=\"nofollow noopener noreferrer\">Feedspot\u003C/a> (Non-free)\u003C/li>\n\u003Cli>\u003Ca href=\"https://feedly.com\" rel=\"nofollow noopener noreferrer\">Feedly\u003C/a> (Non-free)\u003C/li>\n\u003Cli>\u003Ca href=\"https://feedbin.com\" rel=\"nofollow noopener noreferrer\">Feedbin\u003C/a> (Non-free)\u003C/li>\n\u003Cli>\u003Ca href=\"https://theoldreader.com\" rel=\"nofollow noopener noreferrer\">TheOldReader\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://bazqux.com\" rel=\"nofollow noopener noreferrer\">BazQux\u003C/a>\u003C/li>\n\u003C/ul>\n\u003Ch3>Self-hosted Apps\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.commafeed.com/\" rel=\"nofollow noopener noreferrer\">CommaFeed\u003C/a> (Free, OSS)\u003C/li>\n\u003Cli>\u003Ca href=\"https://freshrss.org\" rel=\"nofollow noopener noreferrer\">FreshRSS\u003C/a> (Free, OSS)\u003C/li>\n\u003C/ul>","blog/2022-06-use-rss","ee633c0d-d668-48e5-af57-aaae9d243099",["Date","2022-06-05T00:00:00.000Z"],["Date","2022-06-04T22:01:15.123Z"],[8],"You should be using RSS","Decide exactly what you want to read and escape the social media algorithms. How an old protocol called RSS can give you back the autonomy about what you read.","https://i.imgur.com/t3mebu7.png",[225,34,226],"rss","software","\u003Cp>I often go to social media to get news about topics that interest me. Be it web development, gardening life hacks or political news, I can follow people or topics that interest me. But instead of reading about those topics, I often get sucked into an endless hole of content that I did not sign up for. Social media companies deliberately do not want you to limit what is shown to you. It would be too easy to leave and not spend your time watching their precious ads.\u003C/p>",[34,225,226],{"html":230,"slug":231,"uuid":232,"title":233,"published":10,"date":234,"description":235,"cover_image":236,"content_tags":237,"abstract":241,"tags":242,"links":-1,"type":21,"folder":22},"\u003Cp>There \u003Ca href=\"https://gist.github.com/dentechy/de2be62b55cfd234681921d5a8b6be11\" rel=\"nofollow noopener noreferrer\">are\u003C/a> \u003Ca href=\"https://medium.com/@thinkbynumbers/automatically-start-wsl-ssh-and-various-services-on-windows-845dfda89690\" rel=\"nofollow noopener noreferrer\">many\u003C/a> \u003Ca href=\"https://faun.pub/how-to-setup-ssh-connection-on-ubuntu-windows-subsystem-for-linux-2b36afb943dc\" rel=\"nofollow noopener noreferrer\">guides\u003C/a> on the \u003Ca href=\"https://superuser.com/questions/1112007/how-to-run-ubuntu-service-on-windows-at-startup\" rel=\"nofollow noopener noreferrer\">internet\u003C/a> showing how to set up an SSH server \u003Cstrong>inside\u003C/strong> WSL. This is currently not that easy and in my experience, it is not really stable. An alternative to this is to run the SSH server outside of WSL on the windows side and set its default shell to the WSL shell (or any other shell for that matter).\u003C/p>\n\u003Ch2>Installing the OpenSSH Server\u003C/h2>\n\u003Cp>Windows has been shipping with an OpenSSH client and server for a long time. They are not installed by default but can be activated either in the settings as described \u003Ca href=\"https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse\" rel=\"nofollow noopener noreferrer\">in the official docs\u003C/a> or with the following PowerShell commands.\u003C/p>\n\u003Cp>\u003Cstrong>You will need to start PowerShell as Administrator\u003C/strong>\u003C/p>\n\u003Cp>First, install the OpenSSH client and server.\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-PowerShell\">Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0\nAdd-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0\n\u003C/code>\u003C/pre>\n\u003Cp>Enable the SSH service and make sure the firewall rule is configured:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-PowerShell\"># Enable the service\nStart-Service sshd\nSet-Service -Name sshd -StartupType 'Automatic'\n\n# Confirm the firewall rule is configured. It should be created automatically by setup. Run the following to verify\nif (!(Get-NetFirewallRule -Name \"OpenSSH-Server-In-TCP\" -ErrorAction SilentlyContinue | Select-Object Name, Enabled)) {\n    Write-Output \"Firewall Rule 'OpenSSH-Server-In-TCP' does not exist, creating it...\"\n    New-NetFirewallRule -Name 'OpenSSH-Server-In-TCP' -DisplayName 'OpenSSH Server (sshd)' -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22\n} else {\n    Write-Output \"Firewall rule 'OpenSSH-Server-In-TCP' has been created and exists.\"\n}\n\u003C/code>\u003C/pre>\n\u003Cp>Congratulations, you have installed the SSH server on your Windows machine. And all without manually setting up a background service or modifying config files.\u003C/p>\n\u003Ch2>Setting WSL as Default Shell\u003C/h2>\n\u003Cp>To directly boot into WSL when connecting, we need to change the default shell from \u003Ccode>cmd.exe\u003C/code> or \u003Ccode>PowerShell.exe\u003C/code> to \u003Ccode>bash.exe\u003C/code>, which in turn runs the default WSL distribution. This can be done with the PowerShell command:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-PowerShell\">New-ItemProperty -Path \"HKLM:\\SOFTWARE\\OpenSSH\" -Name DefaultShell -Value \"C:\\WINDOWS\\System32\\bash.exe\" -PropertyType String -Force\n\u003C/code>\u003C/pre>\n\u003Cp>\u003Cstrong>Note\u003C/strong>: even though the shell is running on the Linux side, the SSH server is still on windows. This means you have to use to windows username to log in, and the SCP command copies files relative to the user directory on windows.\u003C/p>\n\u003Ch2>Enable Key-based Authentication (non-Admin User)\u003C/h2>\n\u003Cp>\u003Cstrong>Note\u003C/strong>: If the user account has Admin permissions, read the next chapter, otherwise continue reading.\u003C/p>\n\u003Cp>Create the folder \u003Ccode>.ssh\u003C/code> in the users home directory on windows: (e.g. \u003Ccode>C:\\Users\\&#x3C;username>\\.ssh\u003C/code>). Run the following commands in PowerShell (not as administrator).\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-PowerShell\">New-Item -Path ~\\.ssh -ItmeType \"directory\"\nNew-Item -Path ~\\.ssh\\authorized_keys\n\u003C/code>\u003C/pre>\n\u003Cp>The file \u003Ccode>.ssh\\autzorized_keys\u003C/code> will contain a list of all public keys that shall be allowed to connect to the SSH server.\u003C/p>\n\u003Cp>Copy the contents of your public key file (usually stored in \u003Ccode>~/.ssh/id_rsa.pub\u003C/code>) to the \u003Ccode>authorized_keys\u003C/code> file. If a key is already present, paste your key on a new line.\u003C/p>\n\u003Ch2>Enable Key-based Authentication (Admin User)\u003C/h2>\n\u003Cp>If the user is in the Administrators group, it is not possible to have the \u003Ccode>authorized_keys\u003C/code> file in the user directory for security purposes.\nInstead, it needs to be located on the following path \u003Ccode>%ProgramData%\\ssh\\administrators_authorized_keys\u003C/code>. A second requirement is that it is only accessible to Administrator users, to prevent a normal user from gaining admin permissions.\u003C/p>\n\u003Cp>To create the file start PowerShell as administrator and run the following command.\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-PowerShell\">New-Item -Path $env:programdata\\ssh\\administrators_authorized_keys\n\u003C/code>\u003C/pre>\n\u003Cp>This will create the file with the correct permissions. Now open the file and paste your public key into it. The public key should be located at \u003Ccode>~/.ssh/id_rsa.pub\u003C/code>. If a key is already present, paste your key on a new line.\u003C/p>\n\u003Ch2>Verifying everything works\u003C/h2>\n\u003Cp>Verify that you can SSH into your machine by running the following inside WSL:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">IP=$(cat /etc/resolv.conf | grep nameserver | cut -d \" \" -f2) # get the windows host ip address\nssh &#x3C;user>@$IP\n\u003C/code>\u003C/pre>\n\u003Cp>Or from PowerShell and cmd:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-PowerShell\">ssh &#x3C;user>@localhost\n\u003C/code>\u003C/pre>\n\u003Ch2>Drawbacks\u003C/h2>\n\u003Cp>There are some drawbacks to this approach. If you rely on some programs or scripts to work over SSH, this might not be the method for you. Most scripts expect a unix machine on the other end, or if they expect a windows machine they will most likely not be configured to deal with WSL.\u003C/p>\n\u003Cp>If you however just want to connect to your pc to copy some files or change some settings this approach is perfectly fine.\u003C/p>","blog/2022-03-ssh-windows-wsl","03b5a86c-5f4d-4086-9f5f-e1e46b4bcf58","How to set up an SSH Server on Windows with WSL",["Date","2022-03-02T00:00:00.000Z"],"It can be very helpful to be able to connect to your laptop or desktop PC from anywhere using SSH. I will show you how to easily set this up on Windows with WSL.","/assets/2022-03-ssh-windows-wsl.png",[238,239,240,34],"SSH","WSL","Windows","\u003Cp>There \u003Ca href=\"https://gist.github.com/dentechy/de2be62b55cfd234681921d5a8b6be11\">are\u003C/a> \u003Ca href=\"https://medium.com/@thinkbynumbers/automatically-start-wsl-ssh-and-various-services-on-windows-845dfda89690\">many\u003C/a> \u003Ca href=\"https://faun.pub/how-to-setup-ssh-connection-on-ubuntu-windows-subsystem-for-linux-2b36afb943dc\">guides\u003C/a> on the \u003Ca href=\"https://superuser.com/questions/1112007/how-to-run-ubuntu-service-on-windows-at-startup\">internet\u003C/a> showing how to set up an SSH server \u003Cstrong>inside\u003C/strong> WSL. This is currently not that easy and in my experience, it is not really stable. An alternative to this is to run the SSH server outside of WSL on the windows side and set its default shell to the WSL shell (or any other shell for that matter).\u003C/p>",[34,243,244,103],"ssh","windows",{"html":246,"slug":247,"uuid":248,"title":249,"published":10,"date":250,"description":251,"cover_image":252,"content_tags":253,"abstract":257,"tags":258,"links":-1,"type":21,"folder":22},"\u003Cp>Did you ever want to listen to your phone audio on your PC? I do it all the time to listen to podcasts on my PC without paying for a podcast app that syncs the episodes over the cloud. In this short article I will show you two easy ways to do this with a windows PC.\u003C/p>\n\u003Cp>\u003Cem>TLDR\u003C/em>:\u003C/p>\n\u003Cul>\n\u003Cli>Either use Bluetooth Audio Receiver from the Microsoft Store to connect you phone via Bluetooth,\u003C/li>\n\u003Cli>Or use an audio cable to connect the phone to the \"line-in\" on your PC.\u003C/li>\n\u003C/ul>\n\u003Ch2>Bluetooth (recommended)\u003C/h2>\n\u003Cp>\u003Cstrong>Requirements\u003C/strong>: A PC with integrated Bluetooth or a Bluetooth dongle.\u003C/p>\n\u003Cp>I recommend this approach more than the wired one because it is way less effort, you don't have to deal with a USB or lightning to audio dongle and in my opinion it is more reliable.\u003C/p>\n\u003Cp>Pair your phone with your PC as normal, by opening the Bluetooth settings on your phone and on the PC and wait for the devices to show up. When you successfully paired the phone once you will not have to do this again. Now you need an app that will tell the phone that it can use the PC as a wireless speaker. The only app I found that will do this is the \u003Ca href=\"https://www.microsoft.com/de-de/p/bluetooth-audio-receiver/9n9wclwdqs5j\" rel=\"nofollow noopener noreferrer\">Bluetooth Audio Receiver\u003C/a> app from the Windows Store. Install and and open it. You should see your phone on the list of Bluetooth devices on the app. Select it and click on the \u003Ccode>Open Connection\u003C/code> button. It might take a moment but after it connected, you should hear all sounds from your phone on your PC.\u003C/p>\n\u003Ch2>Wired\u003C/h2>\n\u003Cp>\u003Cstrong>Requirements\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Male-to-Male audio cable (3.5mm audio jack).\u003C/li>\n\u003Cli>A line-in port on your PC (usually blue audio jack on the back)\u003C/li>\n\u003Cli>USB-C to audio jack adapter (Optional)\u003C/li>\n\u003Cli>Lighting to audio jack adapter (Optional)\u003C/li>\n\u003C/ul>\n\u003Cp>This approach works if your PC doesn't support Bluetooth, or if the Bluetooth connection drops for some reason. Connect the audio cable to the blue line-in jack on the back of the computer. Then, connect the phone to the other end of the audio cable. If your phone does not have an audio jack, use the adapter on the USB-C or Lightning port. If your PC detects that you connected a new line-in device, it might open the audio settings automatically. If not, right-click on the volume icon on the taskbar next to the clock and select \u003Ccode>Sounds\u003C/code>. Navigate to the \u003Ccode>Input\u003C/code> tab and double click on the Line-In entry (the one with a cable icon). Navigate to the Monitor tab and select the check box for \"Use this device as a playback source\". This will tell windows it should play all sounds received through this input directly to the speakers. Usually this is used to monitor microphones but it works for this use case too. You should now hear any sound from your phone through your PC headphones or speakers. Make sure you turn this checkbox off when you disconnect your phone. Otherwise you might hear a crackle or other sounds when the loose cable gets touched.\u003C/p>\n\u003Cp>\u003Cem>Photo by Lisa Fotios from Pexels\u003C/em>\u003C/p>","blog/2022-02-phone-audio-to-pc","be57f2df-d58f-4b79-8a51-e20d482f46cf","How to Listen to Phone Audio on PC",["Date","2022-02-12T00:00:00.000Z"],"Learn how to connect your phone audio to your PC over wire or Bluetooth.","/assets/2022-02-phone-audio-to-pc.jpg",[254,255,244,256,226],"how-to","audio","bluetooth","\u003Cp>Did you ever want to listen to your phone audio on your PC? I do it all the time to listen to podcasts on my PC without paying for a podcast app that syncs the episodes over the cloud. In this short article I will show you two easy ways to do this with a windows PC.\u003C/p>",[255,256,254,226,244],{"html":260,"slug":261,"uuid":262,"title":263,"published":10,"description":264,"content_tags":265,"date":269,"modified":270,"cover_image":271,"abstract":272,"tags":273,"links":-1,"type":21,"folder":22},"\u003Ch2>Abstract\u003C/h2>\n\u003Cp>Version control systems use a graph data structure to track revisions of files. Those graphs are mutated with various commands by the respective version control system. The goal of this thesis is to formally define a model of a subset of Git commands which mutate the revision graph, and to model those mutations as a planning task in the Planning Domain Definition Language. Multiple ways to model those graphs will be explored and those models will be compared by testing them using a set of planners.\u003C/p>\n\u003Cp>\u003Ca href=\"https://tiim.ch/assets/2021-01-20-Thesis.pdf\" rel=\"nofollow noopener noreferrer\">Download Thesis\u003C/a>\u003C/p>\n\u003Ch2>Cite\u003C/h2>\n\u003Cpre>\u003Ccode>@thesis{bachmann2021,\n\ttitle        = {Modelling Git Operations as Planning Problems},\n\tauthor       = {Tim Bachmann},\n\tyear         = {2021},\n  month        = {01},\n\ttype         = {Bachelor's Thesis},\n\tschool       = {University of Basel},\n\tdoi          = {10.13140/RG.2.2.24784.17922}\n}\n\u003C/code>\u003C/pre>","blog/2021-01-git-operations-as-planning-problems","dc6e6d10-c460-4d3c-8fe2-4ce7535b4af1","Modelling Git Operations as Planning Problems","Bachelor Thesis. The goal of this thesis is to formally define a model of a subset of Git commands which mutate the revision graph, and to model those mutations as a planning task in the Planning Domain Definition Language. Multiple ways to model those graphs will be explored and those models will be compared by testing them using a set of planners.",[266,267,268,34],"Git","PDDL","Planning-System",["Date","2021-01-20T00:00:00.000Z"],["Date","2023-09-18T11:41:51.000Z"],"/assets/2021-01-git-operations-as-planning-problems.png","\u003Cp>Version control systems use a graph data structure to track revisions of files. Those graphs are mutated with various commands by the respective version control system. The goal of this thesis is to formally define a model of a subset of Git commands which mutate the revision graph, and to model those mutations as a planning task in the Planning Domain Definition Language. Multiple ways to model those graphs will be explored and those models will be compared by testing them using a set of planners.\u003C/p>",[34,274,275,68],"git","pddl",{"html":277,"slug":278,"uuid":279,"title":280,"published":10,"description":281,"content_tags":282,"date":285,"cover_image":286,"abstract":287,"tags":288,"links":-1,"type":21,"folder":22},"\u003Ch2>The problem\u003C/h2>\n\u003Cp>Let's say you have a rest API with the following endpoint that returns all of the books in your database:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-rest\">GET /book/\n\u003C/code>\u003C/pre>\n\u003Cp>Your SQL query might look like something like this\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sql\">SELECT *\nFROM books\n\u003C/code>\u003C/pre>\n\u003Cp>Sometimes you want to only list books, for example, from a specific author. How do we do this in SQL?\u003C/p>\n\u003Ch2>Naive solution: String concatenation \u003C/h2>\n\u003Cp>One way would be to concatenate your sql query something like this:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-js\">const arguments = [];\nconst queryString = \"SELECT * FROM books WHERE true\";\nif (authorFilter != null) {\n  queryString += \"AND author = ?\";\n  arguments.push(authorFilter);\n}\ndb.query(queryString, arguments);\n\u003C/code>\u003C/pre>\n\u003Cp>I'm not much of a fan of manually concatenating strings.\u003C/p>\n\u003Ch2>The coalesce function \u003C/h2>\n\u003Cp>Most Databases have the function \u003Ccode>coalesce\u003C/code> which accepts a variable amount of arguments and returns the first argument that is not null.\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sql\">-- Examle\nSELECT coalesce(null, null, 'tiim.ch', null, '@TiimB') as example;\n\n-- Will return\n\nexample\n---------\ntiim.ch\n\u003C/code>\u003C/pre>\n\u003Cp>But how will this function help us?\u003C/p>\n\u003Ch2>Optional filters with the coalesce function\u003C/h2>\n\u003Cpre>\u003Ccode class=\"language-sql\">SELECT *\nFROM books\nWHERE\n  author = coalesce(?, author);\n\u003C/code>\u003C/pre>\n\u003Cp>If the filter value is null the coalesce expression will resolve to \u003Ccode>author\u003C/code>\nand the comparison \u003Ccode>author = author\u003C/code> will be true.\u003C/p>\n\u003Cp>If on the other hand the value is set for example to Shakespeare then the author will be compared to Shakespeare.\u003C/p>\n\u003Cp>I came across this way to implement optional filters only recently. If you have a more idiomatic way to do this let me know please \u003C/p>\n\u003Cp>If you liked this post please follow me on here or on Twitter under \u003Ca href=\"https://twitter.com/TiimB\" rel=\"nofollow noopener noreferrer\">@TiimB\u003C/a> \u003C/p>","blog/2019-07-sql-optional-filters-coalesce","899fb73c-a78e-4cd9-b712-1886715b2d56","How to write optional filters in SQL","A simple way to filter by optional values in SQL with the COALESCE function.",[283,284,34],"SQL","quick-tip",["Date","2019-07-11T00:00:00.000Z"],"/assets/2019-07-sql-optional-filters-coalesce.png","\u003Cp>Let's say you have a rest API with the following endpoint that returns all of the books in your database:\u003C/p>",[34,284,289],"sql",{"html":291,"slug":292,"uuid":293,"title":294,"published":10,"description":295,"content_tags":296,"date":300,"cover_image":301,"abstract":302,"tags":303,"links":-1,"type":21,"folder":22},"\u003Cp>I recently read the Article \u003Ca href=\"https://blog.usmanity.com/serving-vue-js-apps-on-github-pages/\" rel=\"nofollow noopener noreferrer\">Serving Vue.js apps on GitHub Pages\u003C/a> and it inspired me to write about what I'm doing differently.\u003C/p>\n\u003Cp>If you want to see an example of this method in action, go check out my \u003Ca href=\"https://tiimb.work\" rel=\"nofollow noopener noreferrer\">personal website\u003C/a> on \u003Ca href=\"https://github.com/Tiim/Tiim.github.io\" rel=\"nofollow noopener noreferrer\">GitHub\u003C/a>\u003C/p>\n\u003Cp>I won't be explaining how to setup a Vue project. If you're looking for a Tutorial on that go check out the awesome \u003Ca href=\"https://vuejs.org/v2/guide/\" rel=\"nofollow noopener noreferrer\">Vue.js Guide\u003C/a>.\u003C/p>\n\u003Cp>So you have setup your awesome Vue project and want to host it on GitHub Pages. The way Muhammad explained it you would build the project using \u003Ccode>npm run build\u003C/code>, commit the \u003Ccode>dist/\u003C/code> folder along with your source files and point GitHub to the dist folder. This might get quite messy because you either have commit messages with the sole purpose of uploading the dist folder or you commit the code changes at the same time which makes it hard to find the relevant changes if you ever want to look at your commits again.\u003C/p>\n\u003Cp>So what can you do about this?\u003C/p>\n\u003Cp>Git to the rescue, let's use a branch that contains all the build files.\u003C/p>\n\u003Ch2>Step 1 - keeping our working branch clean \u003C/h2>\n\u003Cp>To make sure that the branch we are working from stays clean of any build files we are gonna add a \u003Ccode>.gitignore\u003C/code> file to the root.\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\"># .gitignore\ndist/\n\u003C/code>\u003C/pre>\n\u003Ch2>Step 2 - adding a second branch \u003C/h2>\n\u003Cp>We are not goint to branch off master like how we would do it if we were to modify our code with the intention to merge it back to the main branch. Instead we are gonna create a squeaky clean new branch that will only ever hold the dist files. After all we will not ever need to merge these two branches together.\u003C/p>\n\u003Cp>We do this by creating a new git repository inside the dist folder:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">cd dist/\ngit init\ngit add .\ngit commit -m 'Deploying my awesome vue app'\n\u003C/code>\u003C/pre>\n\u003Ch2>Step 3 - deploying \u003C/h2>\n\u003Cp>We are gonna force push our new git repository to a branch on GitHub. This might go against git best practices but since we won't ever checkout this branch we don't have to worry about that.\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\">git push -f git@github.com:&#x3C;username>/&#x3C;repo>.git &#x3C;branch>\n\u003C/code>\u003C/pre>\n\u003Cp> Make sure you double or tripple check your destination branch! You don't want to accidentally overwrite your working branch. Using the branch \u003Ccode>gh-pages\u003C/code> will most likely be a good idea.\u003C/p>\n\u003Ch2>Step 4 - pointing GitHub to the right place \u003C/h2>\n\u003Cp>Now we are almost done. The only thing left is telling GitHub where our assets live.\u003C/p>\n\u003Cp>Go to your repo, on the top right navigate to \u003Ccode>Settings\u003C/code> and scroll down to GitHub pages. Enable it and set your source branch to the branch you force pushed to, for example \u003Ccode>gh-pages\u003C/code>.\u003C/p>\n\u003Ch2>Step 5 - automating everything \u003C/h2>\n\u003Cp>If you don't mind doing this whole process (Step 2 and 3) every time you want to deploy you can stop now. If you're as lazy as me, here is the script I use to deploy with one command:\u003C/p>\n\u003Cpre>\u003Ccode class=\"language-sh\"># deploy.sh\n\n#!/usr/bin/env sh\n\n# abort on errors\nset -e\n\n# build\necho Linting..\nnpm run lint\necho Building. this may take a minute...\nnpm run build\n\n# navigate into the build output directory\ncd dist\n\n# if you are deploying to a custom domain\n# echo 'example.com' > CNAME\n\necho Deploying..\ngit init\ngit add -A\ngit commit -m 'deploy'\n\n# deploy\ngit push -f git@github.com:&#x3C;username>/&#x3C;repo>.git &#x3C;branch>\n\ncd -\n\n\u003C/code>\u003C/pre>\n\u003Cp>If your on windows look into the Windows Subsystem for Linus (WSL) it will be worth it.\u003C/p>\n\u003Cp>If you are still reading, thank you very much. This is actually my first article and I'm really happy to hear about any opinions and criticisms.\nHappy Coding \u003C/p>","blog/2019-05-vue-on-github-pages","96054292-eb45-4d8a-9aca-bb050175ff2a","How I use Vue.js on GitHub Pages","How to properly deploy a Vue.js app on GitHub Pages",[297,298,299,34],"GitHub Pages","Vue.js","Javascript",["Date","2019-05-04T00:00:00.000Z"],"/assets/2019-05-vue-on-github-pages.png","\u003Cp>I recently read the Article \u003Ca href=\"https://blog.usmanity.com/serving-vue-js-apps-on-github-pages/\">Serving Vue.js apps on GitHub Pages\u003C/a> and it inspired me to write about what I'm doing differently.\u003C/p>",[34,304,305,306],"github-pages","javascript","vue.js"],"uses":{}}]}
